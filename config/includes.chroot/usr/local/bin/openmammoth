#!/usr/bin/env python3
import os
import sys
import json
import time
import threading
import logging
import ipaddress
import re
import hashlib
import socket
import subprocess
import requests
from datetime import datetime
from scapy.all import *
from scapy.layers.inet import IP, TCP, UDP, ICMP
from colorama import init, Fore, Style
from threading import Lock, RLock
from queue import Queue, Empty
from collections import OrderedDict
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor

# Initialize colorama
init()

class OpenMammoth:
    def __init__(self):
        # Colorama initialization
        init(autoreset=True)
        
        # Set up signal handlers for graceful shutdown
        self._setup_signal_handlers()
        
        # Basic configuration
        self.protection_level = 2
        self.advanced_protection = False
        self.debug_mode = False
        self.interface = None
        self.verbose = True               # Verbosity level for console output
        self.security_level = 2           # Security level for automatic blocking (1-4)
        
        # Thread synchronization locks to prevent race conditions
        self.stats_lock = RLock()          # For safely updating statistics
        self.connection_lock = RLock()     # For connection tracking updates
        self.packet_rates_lock = RLock()   # For packet rate updates
        self.tcp_flags_lock = RLock()      # For TCP flags tracking 
        self.block_list_lock = RLock()     # For IP block list modifications
        self.http_detect_lock = RLock()    # For HTTP attack detection
        self.defense_lock = RLock()        # For defense status modifications
        
        # Thread pool for parallel packet processing - improves throughput on multi-core systems
        self.thread_pool = ThreadPoolExecutor(max_workers=4)  # Adjust based on CPU cores
        
        # Core data structures with thread-safe access - now with OrderedDict for better performance
        self.blocked_ips = OrderedDict()
        
        # Defense status tracking dictionary - initialized with all defenses inactive
        self.defense_status = {
            'syn': False,      # SYN flood protection active
            'udp': False,      # UDP flood protection active
            'icmp': False,     # ICMP flood protection active
            'fragment': False, # Fragment attack protection active
            'dns': False       # DNS amplification protection active
        }
        
        # Runtime statistics - protected by stats_lock
        self.stats = {
            "total_packets": 0,
            "blocked_packets": 0,
            "attacks_detected": 0,
            "port_scans": 0,
            "syn_floods": 0,
            "udp_floods": 0,
            "icmp_floods": 0,
            "dns_amplification": 0,
            "fragment_attacks": 0,
            "malformed_packets": 0,
            "spoofed_ips": 0,
            "threat_intel_blocks": 0,
            "reputation_blocks": 0,
            "dropped_packets": 0,
            "performance_issues": 0,
            "unusual_flags": 0   # Eksik istatistik eklendi
        }
        
        # Connection and packet tracking data structures
        self.connection_tracker = OrderedDict()
        self.packet_rates = OrderedDict()
        
        # Attack detection trackers
        self.syn_tracker = OrderedDict()         # For SYN flood detection
        self.udp_tracker = OrderedDict()         # For UDP flood detection 
        self.icmp_tracker = OrderedDict()        # For ICMP flood detection
        self.tcp_flags_tracker = OrderedDict()   # For unusual TCP flags
        self.port_scan_tracker = OrderedDict()   # For port scan detection
        self.seq_tracker = OrderedDict()         # For TCP sequence prediction attacks
        self.dns_tracker = OrderedDict()         # For DNS amplification attacks
        self.fragment_tracker = OrderedDict()    # For fragment attacks
        self.attack_sources = {}                 # For tracking persistent attackers
        
        # Execution state
        self.is_running = False
        self.capture_thread = None
        self.cleanup_thread = None
        self.update_thread = None
        
        # Performance monitoring and timing variables
        self.high_load = False
        self.last_performance_check = time.time()
        self.last_cleanup_time = time.time()
        self.last_defense_status_report = time.time()  # Initialize defense status report timer
        self.last_portscan_check = time.time()         # Initialize port scan check timer
        self.cleanup_interval = 300  # Clean up every 5 minutes
        
        # Paths and configuration
        self.config_dir = "/etc/securonis"
        
        # Threat intelligence and IP data
        self.threat_intel_db = {}
        self.ip_reputation_db = {}
        self.whitelist = []
        self.blacklist = []
        self.defense_ip_block_list = set()  # For storing IPs that triggered defense mechanisms
        
        # Update settings
        self.use_threat_intel = True
        self.auto_update = True
        self.last_update_check = 0
        self.update_interval = 86400  # 24 hours
        self.local_ips = []
        
        # Check system requirements and ensure root permissions
        if not self.check_root_permissions():
            print(f"{Fore.RED}Error: Root privileges required. Please run with sudo.{Style.RESET_ALL}")
            logging.error("OpenMammoth must be run with root privileges")
            sys.exit(1)
            
        self.check_system_requirements()
        
        if not os.path.exists(self.config_dir):
            try:
                os.makedirs(self.config_dir)
            except PermissionError:
                print(f"{Fore.RED}Error: Permission denied when creating {self.config_dir}{Style.RESET_ALL}")
                print(f"{Fore.YELLOW}Please run the program with root privileges.{Style.RESET_ALL}")
                sys.exit(1)
            except Exception as e:
                print(f"{Fore.RED}Error creating config directory: {str(e)}{Style.RESET_ALL}")
                sys.exit(1)
                
        self.load_config()
        self.setup_logging()
        self.available_interfaces = self.get_available_interfaces()
        self.detect_local_ips()
        self.load_threat_intel()
        self.load_ip_lists()
        
        # Show warning if no interfaces found and wait for user to press Enter
        if not self.available_interfaces:
            os.system('clear')
            print(self.get_ascii_art())
            print(f"\n{Fore.RED}Warning: No network interfaces found!{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}You can configure network interfaces from the main menu.{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}Option 8: Configure Network Interfaces{Style.RESET_ALL}")
            input("\nPress Enter to continue to main menu...")

    def get_ascii_art(self):
        return f"""{Fore.RED}
                                     .                                
                             #@- .=.*%*+:                             
                           @# #%%%%%#####**                           
                          .+ @@###*#*####*%-                          
                        =*@ @@#############%**:                       
                     .@@##@ +-@%###########**##%#:                    
                    %@%*#@# %@%##########*###%####=                   
                    @=%#%% @@@@########%@@%%*##*%#@                   
                   :@#%#%% @@ @@@@@@@@@%..@=*%#*@ @                   
                     .%##@# @@@#  -=. @%@@@+%#*#@                     
                     -*%%@@# @+.@@@@@@@##%##%%#%                      
                      .@ @#@ @ .  -:. +%#%%%#=#=                      
                @-     : @@# @ %@@@@@@@%%%.@@:    : *%                
              @*          :# @ . .--. @### %.         *%              
            -@.            *@@ #@@@@@@@##@%            -#=            
           *#@+           .@ @+.      @###@             %##           
           @#+           .@ -@@ @@@@@@@%###@            =#@           
           @#@+         +@ *@#@   ::. %#=%#*@:-         +#@           
           +##        .@  @@=:@ @@@@@@%%--%####         @*%           
            %##%#-=**-  @@@   %.  .. #%*.  *=##+*:  .:##%%            
             :#%+...=@@@+     -@ @@@@@%:     =#%%###%%%#:             
                :#%%:          @ %--=*@          .--:                 
                              -@ #%#@#@                               
                            -  # @@%**=                               
                            @: #.*.%#@:                               
                           +@  @ @@%#:                                
                           :*%@ #@#%+                                 
                            ##@@@%#                                   
{Style.RESET_ALL}"""

    def setup_logging(self):
        # Create /etc/securonis directory if it doesn't exist
        log_dir = "/etc/securonis"
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)
            
        logging.basicConfig(
            filename=os.path.join(log_dir, 'openmammoth.log'),
            level=logging.DEBUG if self.debug_mode else logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )

    def load_config(self):
        try:
            config_path = os.path.join(self.config_dir, 'config.json')
            with open(config_path, 'r') as f:
                config = json.load(f)
                self.protection_level = config.get('protection_level', 2)
                self.advanced_protection = config.get('advanced_protection', False)
                self.debug_mode = config.get('debug_mode', False)
                self.interface = config.get('interface', None)
                self.use_threat_intel = config.get('use_threat_intel', True)
                self.auto_update = config.get('auto_update', True)
                self.whitelist = config.get('whitelist', [])
                self.blacklist = config.get('blacklist', [])
                self.update_interval = config.get('update_interval', 86400)
                self.last_update_check = config.get('last_update_check', 0)
        except FileNotFoundError:
            self.save_config()
        except json.JSONDecodeError:
            logging.error("Config file is corrupted. Loading defaults.")
            self.save_config()
        except Exception as e:
            logging.error(f"Error loading config: {str(e)}")
            self.save_config()

    def save_config(self):
        config = {
            'protection_level': self.protection_level,
            'advanced_protection': self.advanced_protection,
            'debug_mode': self.debug_mode,
            'interface': self.interface,
            'use_threat_intel': self.use_threat_intel,
            'auto_update': self.auto_update,
            'whitelist': self.whitelist,
            'blacklist': self.blacklist,
            'update_interval': self.update_interval,
            'last_update_check': self.last_update_check
        }
        try:
            config_path = os.path.join(self.config_dir, 'config.json')
            with open(config_path, 'w') as f:
                json.dump(config, f, indent=4)
        except Exception as e:
            logging.error(f"Error saving config: {str(e)}")

    def packet_handler(self, packet):
        # Submit packet to thread pool for parallel processing
        # This allows multiple packets to be processed simultaneously on multi-core systems
        if hasattr(self, 'thread_pool'):
            self.thread_pool.submit(self._process_packet, packet)
        else:
            # Fallback to direct processing if thread pool not available
            self._process_packet(packet)
    
    def _process_packet(self, packet):
        """Internal method to process a packet in a worker thread"""
        start_time = time.time()  # Start timing packet processing performance
        
        # Skip non-IP packets
        if IP not in packet:
            return
            
        # Extract basic packet info for logging and analysis
        try:
            ip_src = packet[IP].src
            ip_dst = packet[IP].dst
                
            # Skip packets to/from whitelisted IPs and local network management
            if ip_src in self.whitelist or ip_dst in self.whitelist:
                return
                
            # Skip internal communications between local IPs
            if ip_src in self.local_ips and ip_dst in self.local_ips:
                return
                
            # Resource management - limit dictionary sizes using thread-safe operations
            try:
                self._enforce_memory_limits()
            except Exception as mem_err:
                logging.error(f"Memory limit enforcement error: {str(mem_err)}")
            
            # Packet drop detection for high traffic environments
            try:
                if self.check_packet_drops(packet):
                    return
            except Exception as drop_err:
                logging.error(f"Error checking packet drops: {str(drop_err)}")
            
            # If process is overloaded, adjust priority
            if hasattr(self, 'high_load') and self.high_load:
                try:
                    self.prioritize_processing()
                except Exception as prio_err:
                    logging.error(f"Error adjusting process priority: {str(prio_err)}")
            
            # Filter whitelisted and local IPs
            try:
                if self.filter_ip(ip_src):
                    return
            except Exception as filter_err:
                logging.error(f"IP filtering error: {str(filter_err)}")
            
            # Check IP reputation and block if needed
            try:
                if self.check_ip_rep_and_block(ip_src):
                    return
            except Exception as rep_err:
                logging.error(f"Error checking IP reputation: {str(rep_err)}")
            
            # Update connection tracking and check rate limits
            try:
                if not self.track_connections_and_rates(ip_src, ip_dst):
                    # Packet dropped due to rate limiting
                    return
            except Exception as track_err:
                logging.error(f"Connection/rate tracking error: {str(track_err)}")
            
            # Application layer attack detection
            try:
                if self.handle_application_layer_attack(packet, ip_src):
                    return
            except Exception as app_err:
                logging.error(f"Application layer analysis error: {str(app_err)}")
                
            # Standard attack detection
            try:
                if self.handle_standard_attacks(packet, ip_src):
                    return
            except Exception as std_err:
                logging.error(f"Standard attack detection error: {str(std_err)}")
                
            # Performance monitoring and stats update
            try:
                self.monitor_performance(start_time)
            except Exception as perf_err:
                logging.error(f"Performance monitoring error: {str(perf_err)}")
                
        except Exception as e:
            # Critical error - top level exception handler ensures packet capture thread never dies
            logging.error(f"Critical error in packet handler: {str(e)}")
            print(f"{Fore.RED}[!] Critical error in packet handler: {str(e)}{Style.RESET_ALL}")
                    
            # Track errors
            with self.stats_lock:
                if not hasattr(self, 'error_count'):
                    self.error_count = 0
                self.error_count += 1
                    
                # Alert on many errors
                if self.error_count % 50 == 0:
                    print(f"{Fore.RED}[!!!] Multiple errors occurring: {self.error_count}. Check logs.{Style.RESET_ALL}")
                    logging.critical(f"Multiple packet handler errors: {self.error_count}. System may be unstable.")
                # End of packet processing

        except Exception as e:
            # Critical error - top level exception handler ensures packet capture thread never dies
            logging.error(f"Critical error in packet handler: {str(e)}")
            print(f"{Fore.RED}[!] Critical error in packet handler: {str(e)}{Style.RESET_ALL}")
            
            # Track errors
            if not hasattr(self, 'error_count'):
                self.error_count = 0
            self.error_count += 1
            
            # Alert on many errors
            if self.error_count % 50 == 0:
                print(f"{Fore.RED}[!!!] Multiple errors occurring: {self.error_count}. Check logs.{Style.RESET_ALL}")
                logging.critical(f"Multiple packet handler errors: {self.error_count}. System may be unstable.")

    def update_connection_tracker(self, ip_src, ip_dst):
        """Update connection tracking information in a thread-safe manner"""
        current_time = time.time()
        
        # Acquire lock to prevent race conditions during multi-threaded operation
        with self.connection_lock:
            if ip_src not in self.connection_tracker:
                self.connection_tracker[ip_src] = {
                    'connections': {},
                    'first_seen': current_time,
                    'last_seen': current_time
                }
            
            if ip_dst not in self.connection_tracker[ip_src]['connections']:
                self.connection_tracker[ip_src]['connections'][ip_dst] = {
                    'count': 1,
                    'first_seen': current_time,
                    'last_seen': current_time
                }
            else:
                self.connection_tracker[ip_src]['connections'][ip_dst]['count'] += 1
                self.connection_tracker[ip_src]['connections'][ip_dst]['last_seen'] = current_time
                
            self.connection_tracker[ip_src]['last_seen'] = current_time
            
            # Check if we need to enforce memory limits during high load
            connection_count = sum(len(src_data.get('connections', {})) 
                                 for src_data in self.connection_tracker.values())
            if connection_count > 50000:  # If tracking more than 50k connections
                self.high_load = True
                
    def update_packet_rates(self, ip):
        """Update packet rate tracking for a specific IP with rate limiting in a thread-safe manner"""
        current_time = time.time()
        packet_allowed = True
        
        # Use thread lock for safe updates in concurrent environments
        with self.packet_rates_lock:
            # Max packets per second for rate limiting (configurable)
            rate_limit = 500  # Default to 500 packets per second from a single IP
            
            if ip not in self.packet_rates:
                self.packet_rates[ip] = {
                    'count': 1,
                    'timestamp': current_time,
                    'dropped': 0  # Track dropped packets for high traffic monitoring
                }
            else:
                if current_time - self.packet_rates[ip]['timestamp'] > 1:
                    # Reset counters for new second but keep track of history
                    dropped = self.packet_rates[ip].get('dropped', 0)
                    self.packet_rates[ip] = {
                        'count': 1,
                        'timestamp': current_time,
                        'dropped': dropped
                    }
                else:
                    # Increment count within the current second
                    self.packet_rates[ip]['count'] += 1
                    
                    # Check for rate limiting
                    if self.packet_rates[ip]['count'] > rate_limit:
                        # This packet exceeds our rate limit
                        self.packet_rates[ip]['dropped'] = self.packet_rates[ip].get('dropped', 0) + 1
                        
                        # Update dropped packets stat with thread safety
                        with self.stats_lock:
                            if 'dropped_packets' not in self.stats:
                                self.stats['dropped_packets'] = 0
                            self.stats['dropped_packets'] += 1
                            
                        # Only log periodically to avoid flooding logs
                        if self.packet_rates[ip]['dropped'] % 100 == 0:
                            logging.warning(f"Rate limiting applied to {ip}: {self.packet_rates[ip]['dropped']} packets dropped")
                            print(f"{Fore.YELLOW}[!] High traffic from {ip}: {self.packet_rates[ip]['dropped']} packets rate limited{Style.RESET_ALL}")
                            
                        packet_allowed = False
        
        return packet_allowed
    def check_application_layer_attacks(self, packet):
        """Detect application layer attacks in HTTP/HTTPS traffic using thread-safe data structures
        Detects: SQLi, XSS, Path Traversal, Command Injection, File Inclusion"""
        if not TCP in packet:
            return False
            
        # Only inspect specific ports for efficiency: HTTP(S), common proxy ports
        http_ports = [80, 443, 8080, 8000, 8008, 8443, 3000, 8888]
        
        if not (packet.haslayer(TCP) and (packet[TCP].dport in http_ports or packet[TCP].sport in http_ports)):
            return False
            
        # Check if packet has payload data
        if not packet.haslayer(Raw):
            return False
            
        # Extract payload for analysis
        payload = str(packet[Raw].load)
        source_ip = packet[IP].src
        
        # Define attack signatures for various application attacks
        attack_signatures = {
            'sql_injection': [
                r"['\"][\s]*OR[\s]*['\"][\s]*=[\s]*['\"]\s*['\"]\s*--",  # OR '='--
                r"['\"][\s]*OR[\s]*\d+[\s]*=[\s]*\d+\s*--",  # OR 1=1--
                r"\bUNION[\s]+SELECT\b",  # UNION SELECT
                r"\bEXEC(?:UTE)?\s+(?:\w+\.)?\.?xp_",  # EXEC xp_
                r"\bINSERT\b.*\bINTO\b.*\bVALUES\b",  # INSERT INTO VALUES
                r"\bSELECT\b.*\bFROM\b.*\bWHERE\b"  # SELECT FROM WHERE
            ],
            'xss': [
                r"<[\s]*script[\s]*>.*?<[\s]*/[\s]*script[\s]*>",  # <script>...</script>
                r"javascript:[\s]*\(",  # javascript:
                r"\bon\w+=['\"].*?['\"]"  # onclick="..."
            ],
            'path_traversal': [
                r"\.\./",  # ../
                r"%2e%2e%2f",  # ../
                r"\\\.\\.\\"  # \..\
            ],
            'command_injection': [
                r"\b(?:;|\||&)+[\s]*(?:(?:c[md]|power)(?:shell)?|bash|sh|python|perl|ruby)\b",
                r"\b(?:;|\||&)+[\s]*(?:cat|echo|rm|cp|mv|touch|wget|curl)\b"
            ],
            'file_inclusion': [
                r"\binclude\(['\"](?:https?|ftp|php|data|expect):", # include("http:
                r"\brequire\(['\"](?:https?|ftp|php|data|expect):", # require("http:
                r"\binclude_once\(['\"](?:https?|ftp|php|data|expect):", # include_once("http:
                r"\brequire_once\(['\"](?:https?|ftp|php|data|expect):" # require_once("http:
            ]
        }
        
        # Use thread-safe tracking for detected attacks
        with self.http_detect_lock:
            # Initialize attack tracking for this IP if not exists
            if not hasattr(self, 'http_attack_tracking'):
                self.http_attack_tracking = {}
                
            if source_ip not in self.http_attack_tracking:
                self.http_attack_tracking[source_ip] = {
                    'sql_injection': 0,
                    'xss': 0,
                    'path_traversal': 0,
                    'command_injection': 0,
                    'file_inclusion': 0,
                    'total': 0,
                    'first_seen': time.time(),
                    'last_seen': time.time()
                }
                
            # Perform signature matching on payload
            detected = False
            attack_types = []
            
            for attack_type, patterns in attack_signatures.items():
                for pattern in patterns:
                    if re.search(pattern, payload, re.IGNORECASE):
                        self.http_attack_tracking[source_ip][attack_type] += 1
                        self.http_attack_tracking[source_ip]['total'] += 1
                        self.http_attack_tracking[source_ip]['last_seen'] = time.time()
                        attack_types.append(attack_type)
                        detected = True
                        break  # Found one pattern of this type, move to next type
            
            # Handle detected attacks
            if detected:
                # Log the attack with details
                attack_str = ", ".join(attack_types)
                logging.warning(f"Application layer attack ({attack_str}) detected from {source_ip}")
                
                # Calculate severity based on attack frequency and variety
                severity = self.http_attack_tracking[source_ip]['total']
                variety = len([t for t, c in self.http_attack_tracking[source_ip].items() 
                           if t not in ['total', 'first_seen', 'last_seen'] and c > 0])
                
                # More diverse attacks = higher severity
                if variety > 1:
                    severity += 10 * variety
                
                # Auto-block for high severity or repeat offenders
                if severity >= 3 or self.http_attack_tracking[source_ip]['total'] >= 5:
                    logging.critical(f"Blocking {source_ip} - Multiple application layer attacks: {attack_str}")
                    return True
            
            return detected
    
    def check_packet_drops(self):
        """Monitor for packet drops in high traffic environments"""
        try:
            with self.stats_lock:
                if hasattr(self, 'last_packet_check') and hasattr(self, 'packet_count'):
                    current_time = time.time()
                    time_diff = current_time - self.last_packet_check
                    
                    if time_diff > 5:  # Check every 5 seconds
                        self.last_packet_check = current_time
                        expected_packets = self.packet_count * 1.1  # Allow 10% variance
                        
                        # Check if received packets match expected count
                        if self.stats['total_packets'] < expected_packets - 1000:  # Significant drop
                            logging.warning(f"Possible packet dropping detected! Expected ~{int(expected_packets)}, got {self.stats['total_packets']}")
                            print(f"{Fore.YELLOW}[!] Possible packet dropping detected! Network may be saturated{Style.RESET_ALL}")
                            
                        self.packet_count = self.stats['total_packets']
                else:
                    self.last_packet_check = time.time()
                    self.packet_count = self.stats['total_packets']
        except Exception as drop_err:
            logging.error(f"Packet drop detection error: {str(drop_err)}")
            
            # Standard attack detection
            try:
                if self.detect_attacks(packet):
                    try:
                        self.block_ip(ip_src, reason="Network attack")
                        self.stats['blocked_packets'] += 1
                        self.stats['attacks_detected'] += 1
                        print(f"{Fore.RED}[!] Attack detected and blocked from: {ip_src}{Style.RESET_ALL}")
                        logging.warning(f"Attack detected and blocked from: {ip_src}")
                    except Exception as block_err:
                        logging.error(f"Error blocking attacker {ip_src}: {str(block_err)}")
            except Exception as detect_err:
                logging.error(f"Attack detection error for packet from {ip_src}: {str(detect_err)}")
            
            # Update stats
            self.stats['total_packets'] += 1
            
            # Performance monitoring for high-speed networks
            processing_time = time.time() - start_time
            if processing_time > 0.01:  # Track performance issues
                if not hasattr(self, 'performance_issues'):
                    self.performance_issues = 0
                self.performance_issues += 1
                
                if self.performance_issues % 100 == 0:
                    logging.warning(f"Performance degradation: {processing_time:.4f}s per packet, may not keep up with gigabit speeds")
                    self.high_load = True
            
            # Periodic reporting
            if self.stats['total_packets'] % 1000 == 0:
                print(f"{Fore.CYAN}[*] Processed {self.stats['total_packets']} packets, blocked {self.stats['blocked_packets']} packets{Style.RESET_ALL}")
        
        except Exception as e:
            # Critical error - top level exception handler ensures packet capture thread never dies
            logging.error(f"Critical error in packet handler: {str(e)}")
            print(f"{Fore.RED}[!] Critical error in packet handler: {str(e)}{Style.RESET_ALL}")
            
            # Track errors
            if not hasattr(self, 'error_count'):
                self.error_count = 0
            self.error_count += 1
            
            # Alert on many errors
            if self.error_count % 50 == 0:
                print(f"{Fore.RED}[!!!] Multiple errors occurring: {self.error_count}. Check logs.{Style.RESET_ALL}")
                logging.critical(f"Multiple packet handler errors: {self.error_count}. System may be unstable.")
                
            # Try to continue processing

    def _enforce_memory_limits(self):
        """Enforce memory limits on tracking dictionaries to prevent unbounded growth"""
        try:
            # Memory limits for various trackers
            max_connections = 10000  # Maximum number of tracked connections
            max_packet_rates = 5000  # Maximum number of tracked IPs for packet rates
            max_tcp_flags = 2000     # Maximum number of IPs tracked for TCP flags
            max_history_items = 100  # Maximum history items per tracking entry
            
            # Use locks to prevent race conditions during cleanup
            with self.connection_lock:
                # Limit connection tracker
                if hasattr(self, 'connection_tracker') and len(self.connection_tracker) > max_connections:
                    # Find oldest entries based on last_seen timestamp
                    sorted_keys = sorted(self.connection_tracker.keys(), 
                                        key=lambda k: self.connection_tracker[k].get('last_seen', 0))
                    # Keep only the newest entries
                    for old_key in sorted_keys[:len(sorted_keys) - max_connections]:
                        del self.connection_tracker[old_key]
                    logging.debug(f"Pruned connection tracker to {max_connections} entries")
            
            with self.packet_rates_lock:
                # Limit packet rates tracker
                if hasattr(self, 'packet_rates') and len(self.packet_rates) > max_packet_rates:
                    # Find oldest entries based on timestamp
                    sorted_ips = sorted(self.packet_rates.keys(), 
                                        key=lambda k: self.packet_rates[k].get('timestamp', 0))
                    # Keep only the newest entries
                    for old_ip in sorted_ips[:len(sorted_ips) - max_packet_rates]:
                        del self.packet_rates[old_ip]
                    logging.debug(f"Pruned packet rates tracker to {max_packet_rates} entries")
            
            with self.tcp_flags_lock:
                # Limit TCP flags tracker
                if hasattr(self, 'tcp_flags_tracker') and len(self.tcp_flags_tracker) > max_tcp_flags:
                    # Find oldest entries based on last_seen timestamp
                    sorted_ips = sorted(self.tcp_flags_tracker.keys(), 
                                        key=lambda k: self.tcp_flags_tracker[k].get('last_seen', 0))
                    # Keep only the newest entries
                    for old_ip in sorted_ips[:len(sorted_ips) - max_tcp_flags]:
                        del self.tcp_flags_tracker[old_ip]
                    logging.debug(f"Pruned TCP flags tracker to {max_tcp_flags} entries")
                    
                # Limit history sizes within trackers
                if hasattr(self, 'tcp_flags_tracker'):
                    for ip in self.tcp_flags_tracker:
                        if len(self.tcp_flags_tracker[ip].get('flags_history', [])) > max_history_items:
                            self.tcp_flags_tracker[ip]['flags_history'] = \
                                self.tcp_flags_tracker[ip]['flags_history'][-max_history_items:]
                            
        except Exception as e:
            logging.error(f"Error enforcing memory limits: {str(e)}")
                
    # Basic filtering - skip whitelisted and local IPs
    # def filter_ip helper method should be defined here
    def check_ip_rep_and_block(self, ip_src):
        """Check IP reputation and block if poor reputation"""
        try:
            reputation_check = self._check_ip_reputation(ip_src)
            if reputation_check and reputation_check.get('score', 100) < 20:
                try:
                    self.block_ip(ip_src, reason="Low reputation score")
                    with self.stats_lock:
                        self.stats['blocked_packets'] += 1
                        self.stats['reputation_blocks'] += 1
                    print(f"{Fore.RED}[!] Blocked low reputation IP: {ip_src} (Score: {reputation_check.get('score', 0)}){Style.RESET_ALL}")
                    logging.warning(f"Blocked low reputation IP: {ip_src} (Score: {reputation_check.get('score', 0)})")
                    return True
                except Exception as block_err:
                    logging.error(f"Error blocking IP {ip_src}: {str(block_err)}")
        except Exception as rep_err:
            logging.error(f"Error checking IP reputation: {str(rep_err)}")
            
        return False
    
    @lru_cache(maxsize=1000)
    def _check_ip_reputation(self, ip):
        """Check IP reputation using local and online databases - now with LRU caching for performance"""
        # Default score and categories
        result = {
            'score': 100,  # Higher is better
            'categories': []
        }
        
        try:
            # Check local reputation database first
            if hasattr(self, 'ip_reputation_db') and ip in self.ip_reputation_db:
                return self.ip_reputation_db[ip]
                
            # Check for known malicious IP patterns
            if self.is_suspicious_ip_pattern(ip):
                result['score'] = 10
                result['categories'].append('suspicious_pattern')
                
            # Check online reputation services if available and not already low score
            if result['score'] > 50 and hasattr(self, 'use_online_reputation') and self.use_online_reputation:
                try:
                    # This would normally call an API but we'll simulate it
                    # to avoid making actual external calls in this example
                    pass
                except Exception:
                    # Fail silently on API errors
                    pass
        except Exception as e:
            logging.error(f"Error in IP reputation check: {str(e)}")
            
        return result
                
    def track_connections_and_rates(self, ip_src, ip_dst):
        """Update connection tracking and enforce rate limiting"""
        # Update tracking with exception handling
        try:
            self.update_connection_tracker(ip_src, ip_dst)
        except Exception as conn_err:
            logging.error(f"Connection tracking error: {str(conn_err)}")
                    
        try:
            # Rate limiting with built-in packet dropping for DoS protection
            return self.update_packet_rates(ip_src)
        except Exception as rate_err:
            logging.error(f"Packet rate tracking error: {str(rate_err)}")
            return True  # Continue processing if rate tracking fails
                
    def handle_application_layer_attack(self, packet, ip_src):
        """Detect and respond to application layer attacks"""
        try:
            if self.check_application_layer_attacks(packet):
                try:
                    self.block_ip(ip_src, reason="Application layer attack")
                    with self.stats_lock:
                        self.stats['blocked_packets'] += 1
                        self.stats['app_layer_attacks'] = self.stats.get('app_layer_attacks', 0) + 1
                    print(f"{Fore.RED}[!] Application layer attack detected from: {ip_src}{Style.RESET_ALL}")
                    logging.warning(f"Application layer attack detected from: {ip_src}")
                    return True
                except Exception as block_err:
                    logging.error(f"Error blocking application layer attacker {ip_src}: {str(block_err)}")
        except Exception as app_err:
            logging.error(f"Application layer analysis error: {str(app_err)}")
            
        return False
                
    def handle_standard_attacks(self, packet, ip_src):
        """Detect and block standard network attacks"""
        try:
            if self.detect_attacks(packet):
                try:
                    self.block_ip(ip_src, reason="Network attack")
                    with self.stats_lock:
                        self.stats['blocked_packets'] += 1
                        self.stats['attacks_detected'] += 1
                    print(f"{Fore.RED}[!] Attack detected and blocked from: {ip_src}{Style.RESET_ALL}")
                    logging.warning(f"Attack detected and blocked from: {ip_src}")
                    return True
                except Exception as block_err:
                    logging.error(f"Error blocking attacker {ip_src}: {str(block_err)}")
        except Exception as detect_err:
            logging.error(f"Attack detection error for packet from {ip_src}: {str(detect_err)}")
        
        return False
                
    def monitor_performance(self, start_time):
        """Monitor packet processing performance and track issues"""
        try:
            with self.stats_lock:
                self.stats['total_packets'] += 1
                    
            # Performance monitoring for high-speed networks
            processing_time = time.time() - start_time
            if processing_time > 0.01:  # Track performance issues
                with self.stats_lock:
                    if not hasattr(self, 'performance_issues'):
                        self.performance_issues = 0
                    self.performance_issues += 1
                            
                    if self.performance_issues % 100 == 0:
                        logging.warning(f"Performance degradation: {processing_time:.4f}s per packet, may not keep up with gigabit speeds")
                        self.high_load = True
                
                # Periodic reporting
                if self.stats['total_packets'] % 1000 == 0:
                    print(f"{Fore.CYAN}[*] Processed {self.stats['total_packets']} packets, blocked {self.stats['blocked_packets']} packets{Style.RESET_ALL}")
        except Exception as e:
            # Critical error - top level exception handler ensures packet capture thread never dies
            logging.error(f"Critical error in packet handler: {str(e)}")
            print(f"{Fore.RED}[!] Critical error in packet handler: {str(e)}{Style.RESET_ALL}")
            
            # Track errors
            if not hasattr(self, 'error_count'):
                self.error_count = 0
            self.error_count += 1
            
            # Alert on many errors
            if self.error_count % 50 == 0:
                print(f"{Fore.RED}[!!!] Multiple errors occurring: {self.error_count}. Check logs.{Style.RESET_ALL}")
                logging.critical(f"Multiple packet handler errors: {self.error_count}. System may be unstable.")
    
    def _enforce_memory_limits(self):
        """Enforce memory limits on tracking dictionaries to prevent unbounded growth"""
        try:
            # Memory limits for various trackers
            max_connections = 10000  # Maximum number of tracked connections
            max_packet_rates = 5000  # Maximum number of tracked IPs for packet rates
            max_tcp_flags = 2000     # Maximum number of IPs tracked for TCP flags
            max_history_items = 100  # Maximum history items per tracking entry
            
            # Limit connection tracker
            if hasattr(self, 'connection_tracker') and len(self.connection_tracker) > max_connections:
                # Remove oldest entries based on timestamp
                sorted_keys = sorted(self.connection_tracker.keys(), 
                                     key=lambda k: self.connection_tracker[k]['timestamp'])
                # Keep only the newest entries
                for old_key in sorted_keys[:len(sorted_keys) - max_connections]:
                    del self.connection_tracker[old_key]
                logging.debug(f"Pruned connection tracker to {max_connections} entries")
                
            # Limit packet rates tracker
            if hasattr(self, 'packet_rates') and len(self.packet_rates) > max_packet_rates:
                # Remove oldest entries based on timestamp
                sorted_ips = sorted(self.packet_rates.keys(), 
                                     key=lambda k: self.packet_rates[k]['timestamp'])
                # Keep only the newest entries
                for old_ip in sorted_ips[:len(sorted_ips) - max_packet_rates]:
                    del self.packet_rates[old_ip]
                logging.debug(f"Pruned packet rates tracker to {max_packet_rates} entries")
            
            # Limit TCP flags tracker
            if hasattr(self, 'tcp_flags_tracker') and len(self.tcp_flags_tracker) > max_tcp_flags:
                # Remove oldest entries based on last_seen
                sorted_ips = sorted(self.tcp_flags_tracker.keys(), 
                                     key=lambda k: self.tcp_flags_tracker[k]['last_seen'])
                # Keep only the newest entries
                for old_ip in sorted_ips[:len(sorted_ips) - max_tcp_flags]:
                    del self.tcp_flags_tracker[old_ip]
                logging.debug(f"Pruned TCP flags tracker to {max_tcp_flags} entries")
                    
            # Limit history sizes within trackers
            if hasattr(self, 'tcp_flags_tracker'):
                for ip in self.tcp_flags_tracker:
                    if len(self.tcp_flags_tracker[ip]['flags_history']) > max_history_items:
                        self.tcp_flags_tracker[ip]['flags_history'] = \
                            self.tcp_flags_tracker[ip]['flags_history'][-max_history_items:]
                            
        except Exception as e:
            logging.error(f"Error enforcing memory limits: {str(e)}")
            print(f"{Fore.RED}[!] Error enforcing memory limits: {str(e)}{Style.RESET_ALL}")
            # Errors here shouldn't stop the program

    def update_connection_tracker(self, ip_src, ip_dst):
        """Update connection tracking information in a thread-safe manner"""
        current_time = time.time()
            
        # Acquire lock to prevent race conditions during multi-threaded operation
        with self.connection_lock:
            if ip_src not in self.connection_tracker:
                self.connection_tracker[ip_src] = {
                    'connections': {},
                    'first_seen': current_time,
                    'last_seen': current_time
                }
            
            if ip_dst not in self.connection_tracker[ip_src]['connections']:
                self.connection_tracker[ip_src]['connections'][ip_dst] = {
                    'count': 1,
                    'first_seen': current_time,
                    'last_seen': current_time
                }
            else:
                self.connection_tracker[ip_src]['connections'][ip_dst]['count'] += 1
                self.connection_tracker[ip_src]['connections'][ip_dst]['last_seen'] = current_time
                    
            self.connection_tracker[ip_src]['last_seen'] = current_time
                
            # Check if we need to enforce memory limits during high load
            connection_count = sum(len(src_data['connections']) for src_data in self.connection_tracker.values())
            if connection_count > 50000:  # If tracking more than 50k connections
                self.high_load = True

    def update_packet_rates(self, ip):
        """Update packet rate tracking for a specific IP with rate limiting"""
        current_time = time.time()
        if ip not in self.packet_rates:
            self.packet_rates[ip] = {
                'count': 1,
                'timestamp': current_time,
                'dropped': 0  # Track dropped packets for high traffic monitoring
            }
        else:
            if current_time - self.packet_rates[ip]['timestamp'] > 1:
                # Reset counters for new second but keep track of history
                dropped = self.packet_rates[ip].get('dropped', 0)
                self.packet_rates[ip] = {
                    'count': 1,
                    'timestamp': current_time,
                    'dropped': dropped
                }
            else:
                # Count for rate limiting
                self.packet_rates[ip]['count'] += 1
                
                # Check for excessively high packet rates (potential DoS)
                if self.packet_rates[ip]['count'] > 1000:  # Configurable threshold
                    # Record dropped packet for statistics
                    self.packet_rates[ip]['dropped'] = self.packet_rates[ip].get('dropped', 0) + 1
                    
                    # Log every 100 dropped packets to avoid log flooding
                    if self.packet_rates[ip]['dropped'] % 100 == 0:
                        logging.warning(f"High traffic rate from {ip}: {self.packet_rates[ip]['count']} packets/sec, "
                                      f"dropped {self.packet_rates[ip]['dropped']} packets")
                    
                    # Record in stats if not exists
                    if not hasattr(self.stats, 'dropped_packets'):
                        self.stats['dropped_packets'] = 0
                    
                    self.stats['dropped_packets'] = self.stats.get('dropped_packets', 0) + 1
                    
                    # Return False to indicate packet should be dropped
                    return False
            
        # Return True to indicate packet processing should continue
        return True

    def detect_attacks(self, packet):
        """Comprehensive attack detection - Integrated with Linux security features"""
        if not IP in packet:
            return False
            
        ip_src = packet[IP].src
        
        # Skip local network traffic completely
        if self.is_local_network(ip_src) or ip_src in self.local_ips:
            return False
        
        # Skip whitelisted IPs
        if self.is_ip_in_whitelist(ip_src):
            return False
        
        # Skip router and gateway IPs (unless configured otherwise)
        if not hasattr(self, 'monitor_routers') or not self.monitor_routers:
            if ip_src.endswith('.1') or ip_src.endswith('.254'):
                return False
                
        # Initialize trackers if needed
        current_time = time.time()
        if not hasattr(self, 'last_defense_status_report'):
            self.last_defense_status_report = current_time
            self.defense_status = {'syn': False, 'udp': False, 'icmp': False, 'fragment': False}
            self.defense_ip_block_list = set()
        
        # Track IP reputation and block if needed
        try:
            reputation_check = self.check_ip_reputation(ip_src)
            if reputation_check and reputation_check.get('score', 100) < 20:  # Very low reputation
                if ip_src not in self.defense_ip_block_list:
                    logging.warning(f"Blocking malicious IP {ip_src}: reputation score {reputation_check.get('score', 0)}/100")
                    # Block IP using iptables if Linux
                    if not hasattr(self, 'security_level') or self.security_level >= 2:
                        try:
                            subprocess.run(
                                f"iptables -A INPUT -s {ip_src} -j DROP", 
                                shell=True, check=True
                            )
                            self.defense_ip_block_list.add(ip_src)
                            logging.info(f"Successfully blocked IP {ip_src} at firewall level")
                            print(f"{Fore.YELLOW}[+] IP {ip_src} blocked at firewall level{Style.RESET_ALL}")
                        except Exception as e:
                            logging.error(f"Failed to block IP {ip_src}: {str(e)}")
                return True
        except Exception as e:
            logging.debug(f"Error checking IP reputation: {str(e)}")
        
        # Check for spoofing attacks first
        if self.check_ip_spoofing(packet):
            self.stats['spoofing_attempts'] += 1
            logging.warning(f"IP spoofing detected from {ip_src}")
            print(f"{Fore.RED}[!] IP Spoofing detected from: {ip_src}{Style.RESET_ALL}")
            
            # Apply Linux-specific defenses
            if not hasattr(self, 'linux_antispoofing_applied') or not self.linux_antispoofing_applied:
                try:
                    # rp_filter = Reverse Path Filtering
                    subprocess.run(
                        "sysctl -w net.ipv4.conf.all.rp_filter=1", 
                        shell=True, check=True
                    )
                    subprocess.run(
                        "sysctl -w net.ipv4.conf.default.rp_filter=1", 
                        shell=True, check=True
                    )
                    logging.info("Successfully enabled Linux kernel reverse path filtering")
                    self.linux_antispoofing_applied = True
                except Exception as e:
                    logging.error(f"Failed to enable Linux anti-spoofing: {str(e)}")
                    
            return True
                
        # Check for fragment attacks
        if self.check_fragment_attack(packet):
            self.stats['fragment_attacks'] += 1
            logging.warning(f"Fragment attack detected from {ip_src}")
            print(f"{Fore.RED}[!] Fragment attack detected from: {ip_src}{Style.RESET_ALL}")
            return True
        
        # Check for flood attacks using enhanced methods
        attack_detected = False
        attack_type = ""
        
        # Check for SYN flood
        if TCP in packet and self.check_syn_flood(packet):
            self.stats['syn_floods'] += 1
            attack_detected = True
            attack_type = "SYN Flood"
            self.defense_status['syn'] = True
                
        # Check for UDP flood
        elif UDP in packet and self.check_udp_flood(packet):
            self.stats['udp_floods'] += 1
            attack_detected = True
            attack_type = "UDP Flood"
            self.defense_status['udp'] = True
                
        # Check for ICMP flood
        elif ICMP in packet and self.check_icmp_flood(packet):
            self.stats['icmp_floods'] += 1
            attack_detected = True
            attack_type = "ICMP Flood"
            self.defense_status['icmp'] = True
        
        # If any attack detected, add to tracking and log    
        if attack_detected:
            # Track attack source
            if not hasattr(self, 'attack_sources'):
                self.attack_sources = {}
                
            if ip_src not in self.attack_sources:
                self.attack_sources[ip_src] = {
                    'first_attack': current_time,
                    'last_attack': current_time,
                    'types': {attack_type: 1},
                    'blocked': False
                }
            else:
                self.attack_sources[ip_src]['last_attack'] = current_time
                if attack_type in self.attack_sources[ip_src]['types']:
                    self.attack_sources[ip_src]['types'][attack_type] += 1
                else:
                    self.attack_sources[ip_src]['types'][attack_type] = 1
                    
            # Log the detected attack
            logging.warning(f"{attack_type} detected from {ip_src}")
            print(f"{Fore.RED}[!] {attack_type} detected from: {ip_src}{Style.RESET_ALL}")
            
            # For persistent offenders, block at Linux firewall level
            if hasattr(self, 'security_level') and self.security_level >= 3:
                source_data = self.attack_sources[ip_src]
                attack_types = len(source_data['types'])
                total_attacks = sum(source_data['types'].values())
                
                if attack_types > 2 or total_attacks > 5:
                    if not source_data['blocked'] and ip_src not in self.defense_ip_block_list:
                        try:
                            # Shell injection tehlikesini önlemek için shell=False kullanıyoruz
                            # ve IP adresini bir argüman olarak geçiyoruz
                            # Öncesinde IP adresinin geçerli olup olmadığını doğruluyoruz
                            try:
                                # IP doğrulaması
                                ipaddress.ip_address(ip_src)
                                # Güvenli çalıştırma yöntemi
                                subprocess.run(
                                    ['iptables', '-A', 'INPUT', '-s', ip_src, '-j', 'DROP'],
                                    shell=False, check=True
                                )
                                source_data['blocked'] = True
                                self.defense_ip_block_list.add(ip_src)
                            except ValueError:
                                # Geçersiz IP adresi
                                logging.error(f"Invalid IP address attempted to be blocked: {ip_src}")
                                print(f"{Fore.RED}[!] Invalid IP address detected: {ip_src}{Style.RESET_ALL}")
                                return True  # IP geçerli değil ama yine de saldırı tespitini tamamla
                            logging.info(f"Persistent attacker {ip_src} blocked at firewall level")
                            print(f"{Fore.YELLOW}[+] Persistent attacker {ip_src} blocked at firewall level{Style.RESET_ALL}")
                        except Exception as e:
                            logging.error(f"Failed to block persistent attacker {ip_src}: {str(e)}")
            
            return True
            
        # Check for unusual TCP flags combinations (advanced scan techniques)
        if TCP in packet and self.check_unusual_tcp_flags(packet):
            if not 'unusual_flags' in self.stats:
                self.stats['unusual_flags'] = 0
            self.stats['unusual_flags'] += 1
            logging.warning(f"Unusual TCP flags pattern detected from {ip_src}")
            print(f"{Fore.RED}[!] Advanced scan technique detected from: {ip_src}{Style.RESET_ALL}")
            
            # Add to defense block list for persistent offenders
            if ip_src not in self.defense_ip_block_list:
                self.defense_ip_block_list.add(ip_src)
                
            return True
            
        # Periodically check port scans (separate from flood attacks)
        if hasattr(self, 'last_portscan_check'):
            if current_time - self.last_portscan_check > 10:  # Every 10 seconds
                self.last_portscan_check = current_time
                if self.check_port_scan(ip_src):
                    self.stats['port_scans'] += 1
                    logging.warning(f"Port scan detected from {ip_src}")
                    print(f"{Fore.RED}[!] Port scan detected from: {ip_src}{Style.RESET_ALL}")
                    return True
        else:
            self.last_portscan_check = current_time
            
        # Status reporting for defense mechanisms
        if current_time - self.last_defense_status_report > 300:  # Every 5 minutes
            self.last_defense_status_report = current_time
            active_defenses = []
            
            # Thread-safe access to defense_status dictionary
            with self.defense_lock:  # Using existing defense_lock or need to add it if not exists
                if self.defense_status.get('syn', False):  
                    active_defenses.append("SYN flood protection")
                if self.defense_status.get('udp', False):
                    active_defenses.append("UDP flood protection")
                if self.defense_status.get('icmp', False):
                    active_defenses.append("ICMP flood protection")
                if self.defense_status.get('fragment', False):
                    active_defenses.append("Fragment attack protection")
            
            # Actually use the active_defenses information
            if active_defenses:
                defense_msg = f"Active defenses: {', '.join(active_defenses)}"
                logging.info(defense_msg)
                if self.verbose:
                    print(f"{Fore.CYAN}[INFO] {defense_msg}{Style.RESET_ALL}")
                
        # No attack detected
        return False
        
    def check_syn_flood(self, packet):
        """Enhanced SYN flood detection with Linux-specific defenses"""
        # Ensure it's a TCP packet
        if not TCP in packet:
            return False
            
        # Check for SYN flag
        if not packet[TCP].flags & 0x02:
            return False
            
        ip_src = packet[IP].src
        tcp_dport = packet[TCP].dport
        current_time = time.time()
        
        # Using lock to prevent race conditions
        with self.tcp_flags_lock:
            # Initialize SYN flood trackers if not exists
            if not hasattr(self, 'syn_tracker'):
                self.syn_tracker = {}
                self.linux_sysctl_applied = False
            
            # Initialize or update SYN count for this source IP
            if ip_src not in self.syn_tracker:
                self.syn_tracker[ip_src] = {
                    'count': 1, 
                    'first_syn': current_time,
                    'last_syn': current_time,
                    'ports': {tcp_dport: 1},
                    'completed': 0
                }
            else:
                # Update existing tracker
                tracker = self.syn_tracker[ip_src]
                tracker['count'] += 1
                tracker['last_syn'] = current_time
                
                # Track targeted ports
                if tcp_dport in tracker['ports']:
                    tracker['ports'][tcp_dport] += 1
                else:
                    tracker['ports'][tcp_dport] = 1
            
            # Calculate metrics for detection
            tracker = self.syn_tracker[ip_src]
            syn_count = tracker['count']
            time_window = current_time - tracker['first_syn']
            ports_targeted = len(tracker['ports'])
            syn_rate = syn_count / max(time_window, 0.1)  # Avoid division by zero
            
            # Attack Pattern 1: High rate of SYN packets - with improved thresholds to reduce false positives
            if time_window > 2 and syn_rate > 150 and syn_count > 300:  # More strict conditions
                # Additional check for legitimate connections
                if ip_src in self.whitelist or self._check_legitimate_connection(ip_src):
                    logging.debug(f"Ignored potential false positive SYN detection from whitelisted/legitimate IP {ip_src}")
                    return False
                    
                self._activate_linux_defenses()
                logging.warning(f"SYN flood detected from {ip_src}: {syn_count} SYNs in {time_window:.2f}s, rate: {syn_rate:.2f}/s")
                return True
            
            # Attack Pattern 2: Multiple ports targeted quickly - with context awareness
            if ports_targeted > 30 and time_window < 5 and syn_count > 100:  # More restrictive
                # Check if this might be legitimate service discovery or application behavior
                if self._is_common_port_pattern(tracker['ports']):
                    logging.debug(f"Ignored potential false positive port scan from {ip_src} - matches common pattern")
                    return False
                    
                self._activate_linux_defenses()
                logging.warning(f"Fast port scan or distributed SYN flood from {ip_src}: targeting {ports_targeted} ports in {time_window:.2f}s")
                return True
                
            # Reset tracker if window is too large to avoid stale data
            if time_window > 60:  # 1 minute window
                self.syn_tracker[ip_src] = {
                    'count': 1, 
                    'first_syn': current_time,
                    'last_syn': current_time,
                    'ports': {tcp_dport: 1},
                    'completed': 0
                }
                
            # Clean up trackers periodically
                if hasattr(self, 'last_syn_cleanup') and current_time - getattr(self, 'last_syn_cleanup', 0) > 60:
                    self.last_syn_cleanup = current_time
                    stale_ips = []
                    for ip, data in self.syn_tracker.items():
                        if current_time - data.get('last_syn', 0) > 300:  # 5 minutes
                            stale_ips.append(ip)
                    
                    for ip in stale_ips:
                        del self.syn_tracker[ip]
                        
                    if stale_ips:
                        logging.debug(f"Cleaned up {len(stale_ips)} stale SYN trackers")
            
        return False
    
    def _check_legitimate_connection(self, ip_src):
        """Determine if an IP is likely a legitimate connection even with high traffic
        
        This reduces false positives by checking if the IP has shown normal connection patterns before,
        is a known service, or is communicating with established sessions
        """
        try:
            # Check if we have connection history for this IP
            if hasattr(self, 'connection_tracker') and ip_src in self.connection_tracker:
                conn_data = self.connection_tracker[ip_src]
                
                # If we've seen completed handshakes from this IP, it's likely legitimate
                if conn_data.get('completed_handshakes', 0) > 5:
                    return True
                    
                # If we've seen successful data transfer, it's likely legitimate
                if conn_data.get('data_packets', 0) > 10:
                    return True
            
            # Check if it's a common service port that might have burst traffic
            if hasattr(self, 'tcp_flags_tracker') and ip_src in self.tcp_flags_tracker:
                ports = self.tcp_flags_tracker[ip_src].get('ports_targeted', {})
                service_ports = {80, 443, 8080, 8443, 22, 25, 53, 110, 143, 993, 995}
                
                # If communication is primarily with standard service ports
                if ports and all(port in service_ports for port in ports):
                    return True
            
            return False
            
        except Exception as e:
            logging.error(f"Error in legitimate connection check for {ip_src}: {str(e)}")
            return False
            
    def _is_common_port_pattern(self, ports):
        """Check if the port access pattern matches known legitimate service discovery
        
        This reduces false positives for services like web browsers that may access multiple
        ports in quick succession for legitimate reasons
        """
        try:
            # No ports to check
            if not ports:
                return False
                
            # Common patterns we want to whitelist
            common_patterns = [
                # Web browsing pattern (HTTP, HTTPS, alt HTTP ports)
                {80, 443, 8080, 8443},
                # Email pattern (SMTP, IMAP, POP3, secure variants)
                {25, 143, 110, 993, 995},
                # DNS and web combined
                {53, 80, 443}
            ]
            
            # Get the set of ports being accessed
            port_set = set(ports.keys())
            
            # Check if this matches any of our common patterns
            for pattern in common_patterns:
                # If the intersection covers most of the accessed ports, likely legitimate
                intersection = pattern & port_set
                if len(intersection) >= min(3, len(port_set)):
                    return True
                    
            # Check if ports are in a narrow range (possible service discovery)
            if port_set and max(port_set) - min(port_set) < 20 and len(port_set) < 15:
                return True
                
            return False
            
        except Exception as e:
            logging.error(f"Error in common port pattern check: {str(e)}")
            return False
    
    def _activate_linux_defenses(self):
        """Activate Linux kernel defenses against SYN flood attacks"""
        if not hasattr(self, 'linux_sysctl_applied') or not self.linux_sysctl_applied:
            try:
                # TCP SYN cookie protection
                subprocess.run(['sysctl', '-w', 'net.ipv4.tcp_syncookies=1'], check=True)
                # Reduce SYN-ACK retries
                subprocess.run(['sysctl', '-w', 'net.ipv4.tcp_synack_retries=2'], check=True)
                # Increase backlog queue
                subprocess.run(['sysctl', '-w', 'net.ipv4.tcp_max_syn_backlog=2048'], check=True)
                # Enable protection against time-wait assassination
                subprocess.run(['sysctl', '-w', 'net.ipv4.tcp_rfc1337=1'], check=True)
                # Drop ICMP redirects
                subprocess.run(['sysctl', '-w', 'net.ipv4.conf.all.accept_redirects=0'], check=True)
                # Log martian packets
                subprocess.run(['sysctl', '-w', 'net.ipv4.conf.all.log_martians=1'], check=True)
                
                self.linux_sysctl_applied = True
                logging.info("Linux kernel defenses activated against SYN flood attacks")
            except Exception as e:
                logging.error(f"Failed to activate Linux kernel defenses: {str(e)}")
    

    def check_udp_flood(self, packet):
        """Advanced UDP flood attack detection and Linux defense"""
        if not (IP in packet and UDP in packet):
            return False
            
        ip_src = packet[IP].src
        udp_dport = packet[UDP].dport
        pkt_len = len(packet)
        current_time = time.time()
        
        # Initialize UDP flood trackers if not exists
        if not hasattr(self, 'udp_tracker'):
            self.udp_tracker = {}
            self.udp_ports_tracker = {}
            self.common_udp_ports = [53, 123, 161, 1900, 5353]  # Common UDP service ports
            self.linux_udp_defense_applied = False
        
        # Initialize or update UDP count for this source IP
        if ip_src not in self.udp_tracker:
            self.udp_tracker[ip_src] = {
                'count': 1, 
                'first_packet': current_time,
                'last_packet': current_time,
                'ports': {udp_dport: 1},
                'bytes': pkt_len,
                'amplification_candidate': False
            }
        else:
            # Update existing tracker
            tracker = self.udp_tracker[ip_src]
            tracker['count'] += 1
            tracker['last_packet'] = current_time
            tracker['bytes'] += pkt_len
            
            # Track targeted ports
            if udp_dport in tracker['ports']:
                tracker['ports'][udp_dport] += 1
            else:
                tracker['ports'][udp_dport] = 1
                
        # Track UDP ports (for service port floods)
        if udp_dport not in self.udp_ports_tracker:
            self.udp_ports_tracker[udp_dport] = {
                'count': 1,
                'sources': {ip_src: 1},
                'first_packet': current_time,
                'is_service': udp_dport in self.common_udp_ports
            }
        else:
            port_tracker = self.udp_ports_tracker[udp_dport]
            port_tracker['count'] += 1
            if ip_src in port_tracker['sources']:
                port_tracker['sources'][ip_src] += 1
            else:
                port_tracker['sources'][ip_src] = 1
        
        # Calculate metrics for detection
        tracker = self.udp_tracker[ip_src]
        udp_count = tracker['count']
        time_window = current_time - tracker['first_packet']
        ports_targeted = len(tracker['ports'])
        bytes_per_second = tracker['bytes'] / max(time_window, 0.1)  # Avoid division by zero
        packets_per_second = udp_count / max(time_window, 0.1)
        
        # Look for UDP amplification pattern:
        # Common pattern: small packets to port 53 (DNS), 123 (NTP), 161 (SNMP), etc.
        if udp_dport in self.common_udp_ports and pkt_len < 100:
            tracker['amplification_candidate'] = True
        
        # Attack Pattern 1: High packet rate to single source
        if time_window > 1 and packets_per_second > 500:  # More than 500 UDP packets per second
            self._activate_linux_udp_defenses()
            logging.warning(f"UDP flood detected from {ip_src}: {udp_count} packets in {time_window:.2f}s, rate: {packets_per_second:.2f}/s")
            return True
        
        # Attack Pattern 2: High bandwidth usage
        if bytes_per_second > 1000000:  # More than 1 MB/s
            self._activate_linux_udp_defenses()
            logging.warning(f"UDP bandwidth flood from {ip_src}: {bytes_per_second/1024/1024:.2f} MB/s")
            return True
            
        # Attack Pattern 3: Multiple ports targeted quickly (UDP port scan)
        if ports_targeted > 30 and time_window < 10:
            logging.warning(f"UDP port scan from {ip_src}: targeting {ports_targeted} ports in {time_window:.2f}s")
            return True
            
        # Attack Pattern 4: Service-specific UDP flood (targeting specific services)
        for port, port_data in self.udp_ports_tracker.items():
            if port_data['is_service'] and current_time - port_data['first_packet'] < 5:
                # If many sources target the same service port in short time
                if len(port_data['sources']) > 20:
                    self._activate_linux_udp_defenses()
                    logging.warning(f"Distributed UDP flood detected on service port {port}: {len(port_data['sources'])} sources")
                    return True
                # If one source sends many packets to a service port
                elif port_data['count'] > 300 and len(port_data['sources']) < 5:
                    self._activate_linux_udp_defenses()
                    logging.warning(f"UDP service flood detected on port {port}: {port_data['count']} packets")
                    return True
            
        # Reset tracker if window is too large to avoid stale data
        if time_window > 60:  # 1 minute window
            self.udp_tracker[ip_src] = {
                'count': 1, 
                'first_packet': current_time,
                'last_packet': current_time,
                'ports': {udp_dport: 1},
                'bytes': pkt_len,
                'amplification_candidate': tracker.get('amplification_candidate', False)
            }
            
        # Clean up trackers periodically
        if hasattr(self, 'last_udp_cleanup') and current_time - getattr(self, 'last_udp_cleanup', 0) > 60:
            self.last_udp_cleanup = current_time
            
            # Clean IP trackers
            stale_ips = []
            for ip, data in self.udp_tracker.items():
                if current_time - data.get('last_packet', 0) > 300:  # 5 minutes
                    stale_ips.append(ip)
            
            for ip in stale_ips:
                del self.udp_tracker[ip]
                
            # Clean port trackers
            stale_ports = []
            for port, data in self.udp_ports_tracker.items():
                if current_time - data.get('first_packet', 0) > 300:  # 5 minutes
                    stale_ports.append(port)
            
            for port in stale_ports:
                del self.udp_ports_tracker[port]
                
            if stale_ips or stale_ports:
                logging.debug(f"Cleaned up {len(stale_ips)} stale UDP IP trackers and {len(stale_ports)} port trackers")
                
        return False
        
    def _activate_linux_udp_defenses(self):
        """Activate Linux kernel defenses against UDP flood attacks"""
        if hasattr(self, 'linux_udp_defense_applied') and self.linux_udp_defense_applied:
            return  # Already applied
            
        try:
            # Common Linux sysctl settings to mitigate UDP floods
            sysctl_commands = [
                # Increase UDP buffer sizes
                'sysctl -w net.core.rmem_max=16777216',  # 16MB max receive buffer
                'sysctl -w net.core.wmem_max=16777216',  # 16MB max send buffer
                # Set UDP memory pressure thresholds
                'sysctl -w net.ipv4.udp_mem="262144 327680 393216"',
                # Connectivity tracking hardening
                'sysctl -w net.netfilter.nf_conntrack_udp_timeout=10',        # Seconds
                'sysctl -w net.netfilter.nf_conntrack_udp_timeout_stream=30', # Seconds
                # Rate limit ICMP so attackers can't simply block your ICMP messages
                'sysctl -w net.ipv4.icmp_ratelimit=1000',
                # If DNS server present, limit responses to help prevent amplification
                'if command -v named &> /dev/null; then rndc recursing; fi'
            ]
            
            for cmd in sysctl_commands:
                try:
                    subprocess.run(cmd, shell=True, check=True)
                except Exception as e:
                    logging.error(f"Failed to run UDP defense command '{cmd}': {str(e)}")
                
            logging.info("Successfully activated Linux kernel UDP flood defenses")
            self.linux_udp_defense_applied = True
        except Exception as e:
            logging.error(f"Failed to activate Linux UDP defenses: {str(e)}")
            self.linux_udp_defense_applied = False
        return False

    def check_icmp_flood(self, packet):
        """Advanced ICMP flood attack detection and Linux defense"""
        if not (IP in packet and ICMP in packet):
            return False
            
        ip_src = packet[IP].src
        icmp_type = packet[ICMP].type
        icmp_code = packet[ICMP].code
        pkt_len = len(packet)
        current_time = time.time()
        
        # Initialize ICMP flood trackers if not exists
        if not hasattr(self, 'icmp_tracker'):
            self.icmp_tracker = {}
            # Common ICMP types we want to track specifically
            self.icmp_types = {
                0: "Echo Reply",
                3: "Destination Unreachable",
                8: "Echo Request", 
                11: "Time Exceeded",
                13: "Timestamp",
                15: "Information Request",
                17: "Address Mask Request"
            }
            # Initialize Linux defense flag
            self.linux_icmp_defense_applied = False
            
        # Create type-code key for detailed tracking
        type_code = f"{icmp_type}-{icmp_code}"
        
        # Initialize or update ICMP count for this source IP
        if ip_src not in self.icmp_tracker:
            self.icmp_tracker[ip_src] = {
                'count': 1, 
                'first_packet': current_time,
                'last_packet': current_time,
                'bytes': pkt_len,
                'types': {type_code: 1}
            }
        else:
            # Update existing tracker
            tracker = self.icmp_tracker[ip_src]
            tracker['count'] += 1
            tracker['last_packet'] = current_time
            tracker['bytes'] += pkt_len
            
            # Track ICMP types/codes
            if type_code in tracker['types']:
                tracker['types'][type_code] += 1
            else:
                tracker['types'][type_code] = 1
        
        # Calculate metrics for detection
        tracker = self.icmp_tracker[ip_src]
        icmp_count = tracker['count']
        time_window = current_time - tracker['first_packet']
        bytes_per_second = tracker['bytes'] / max(time_window, 0.1)  # Avoid division by zero
        packets_per_second = icmp_count / max(time_window, 0.1)
        distinct_types = len(tracker['types'])
        
        # Attack Pattern 1: High rate of ICMP packets
        # This is the classic ICMP flood pattern
        if time_window > 1 and packets_per_second > 100:  # More than 100 ICMP packets per second
            self._activate_linux_icmp_defenses()
            logging.warning(f"ICMP flood detected from {ip_src}: {icmp_count} packets in {time_window:.2f}s, rate: {packets_per_second:.2f}/s")
            return True
            
        # Attack Pattern 2: High bandwidth usage (ICMP bandwidth flood)
        if bytes_per_second > 500000:  # More than 500 KB/s of ICMP traffic
            self._activate_linux_icmp_defenses()
            logging.warning(f"ICMP bandwidth flood from {ip_src}: {bytes_per_second/1024:.2f} KB/s")
            return True
            
        # Attack Pattern 3: Echo request flood (ping flood)
        if icmp_type == 8 and time_window > 2:  # Echo request
            echo_count = tracker['types'].get(f"8-0", 0)
            echo_rate = echo_count / time_window
            if echo_rate > 50:  # More than 50 echo requests per second
                self._activate_linux_icmp_defenses()
                logging.warning(f"ICMP ping flood from {ip_src}: {echo_count} echo requests in {time_window:.2f}s")
                return True
                
        # Attack Pattern 4: ICMP type scan or unusual ICMP types
        if distinct_types > 5 and time_window < 60:  # Many different ICMP types in short period
            logging.warning(f"ICMP type scan from {ip_src}: {distinct_types} different ICMP types")
            return True
            
        # Attack Pattern 5: Amplification or DoS via broadcast ping
        if icmp_type == 8 and pkt_len > 1000:  # Large ICMP echo request
            self._activate_linux_icmp_defenses()
            logging.warning(f"Large ICMP packet from {ip_src}: {pkt_len} bytes, possible amplification attack")
            return True
            
        # Reset tracker if window is too large to avoid stale data
        if time_window > 120:  # 2 minute window
            self.icmp_tracker[ip_src] = {
                'count': 1, 
                'first_packet': current_time,
                'last_packet': current_time,
                'bytes': pkt_len,
                'types': {type_code: 1}
            }
            
        # Clean up trackers periodically
        if hasattr(self, 'last_icmp_cleanup') and current_time - getattr(self, 'last_icmp_cleanup', 0) > 120:
            self.last_icmp_cleanup = current_time
            
            # Clean IP trackers
            stale_ips = []
            for ip, data in self.icmp_tracker.items():
                if current_time - data.get('last_packet', 0) > 300:  # 5 minutes
                    stale_ips.append(ip)
            
            for ip in stale_ips:
                del self.icmp_tracker[ip]
                
            if stale_ips:
                logging.debug(f"Cleaned up {len(stale_ips)} stale ICMP trackers")
                
        return False
        
    def _activate_linux_icmp_defenses(self):
        """Activate Linux kernel defenses against ICMP flood attacks"""
        if hasattr(self, 'linux_icmp_defense_applied') and self.linux_icmp_defense_applied:
            return  # Already applied
            
        try:
            # Common Linux sysctl settings to mitigate ICMP floods
            sysctl_commands = [
                # Ignore broadcasts to prevent smurf attacks
                'sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1',
                # Set rate limit for ICMP errors
                'sysctl -w net.ipv4.icmp_ratelimit=100',
                # Ignore bogus ICMP errors
                'sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1',
                # Rate limit logging of invalid addresses
                'sysctl -w net.ipv4.conf.all.log_martians=0',
                # For advanced protection, we can completely ignore ping requests
                # This is done only if the attack persists
                # 'sysctl -w net.ipv4.icmp_echo_ignore_all=1',
            ]
            
            for cmd in sysctl_commands:
                try:
                    subprocess.run(cmd, shell=True, check=True)
                except Exception as e:
                    logging.error(f"Failed to run ICMP defense command '{cmd}': {str(e)}")
            
            # Also apply iptables rules for ICMP rate limiting
            icmp_iptables_cmds = [
                # Rate limit ICMP to 5/second with burst of 10
                'iptables -A INPUT -p icmp --icmp-type echo-request -m limit --limit 5/second --limit-burst 10 -j ACCEPT',
                'iptables -A INPUT -p icmp --icmp-type echo-request -j DROP'
            ]
            
            for cmd in icmp_iptables_cmds:
                try:
                    subprocess.run(cmd, shell=True, check=True)
                except Exception as e:
                    logging.error(f"Failed to run ICMP iptables command '{cmd}': {str(e)}")
                
            logging.info("Successfully activated Linux kernel ICMP flood defenses")
            self.linux_icmp_defense_applied = True
        except Exception as e:
            logging.error(f"Failed to activate Linux ICMP defenses: {str(e)}")
            self.linux_icmp_defense_applied = False
        return False

    def check_port_scan(self, ip, threshold_multiplier=1.0):
        """Advanced port scan detection"""
        if not hasattr(self, 'port_scan_tracker'):
            self.port_scan_tracker = {}
            
        current_time = time.time()
        scan_window = 60  # 60-second window
        short_window = 5   # 5-second window for fast scans
        unique_ports = set()
        recent_ports = set()  # For very recent connections (fast scan)
        tcp_syn_ports = set()  # For SYN scans
        tcp_fin_ports = set()  # For FIN scans
        tcp_null_ports = set() # For NULL scans
        tcp_xmas_ports = set() # For XMAS scans
        udp_ports = set()      # For UDP scans
        
        # Get all recent connection attempts from this IP
        for conn in self.connection_tracker:
            if ip in conn:
                conn_time = self.connection_tracker[conn]['timestamp']
                if current_time - conn_time < scan_window:
                    parts = conn.split('-')
                    if len(parts) >= 2:
                        try:
                            port_info = parts[1].split(':')
                            if len(port_info) >= 2:
                                port = port_info[-1]
                                unique_ports.add(port)
                                
                                # Check for very recent connections (possible fast scan)
                                if current_time - conn_time < short_window:
                                    recent_ports.add(port)
                                    
                                # Track connection type if available
                                if len(parts) >= 3 and 'type' in parts[2]:
                                    conn_type = parts[2]['type']
                                    if conn_type == 'tcp_syn':
                                        tcp_syn_ports.add(port)
                                    elif conn_type == 'tcp_fin':
                                        tcp_fin_ports.add(port)
                                    elif conn_type == 'tcp_null':
                                        tcp_null_ports.add(port)
                                    elif conn_type == 'tcp_xmas':
                                        tcp_xmas_ports.add(port)
                                    elif conn_type == 'udp':
                                        udp_ports.add(port)
                        except Exception:
                            pass  # Malformed connection key
        
        # Initialize or update port scan tracker
        if ip not in self.port_scan_tracker:
            self.port_scan_tracker[ip] = {
                'first_seen': current_time,
                'last_seen': current_time,
                'port_count': len(unique_ports),
                'port_history': list(unique_ports),
                'scan_detection_count': 0
            }
        else:
            # Update the tracker
            tracker = self.port_scan_tracker[ip]
            tracker['last_seen'] = current_time
            tracker['port_count'] = max(tracker['port_count'], len(unique_ports))
            
            # Update port history (keep only most recent 100 ports)
            new_ports = [p for p in unique_ports if p not in tracker['port_history']]
            tracker['port_history'].extend(new_ports)
            if len(tracker['port_history']) > 100:
                tracker['port_history'] = tracker['port_history'][-100:]
        
        # Different detection methods
        scan_detected = False
        
        # Method 1: Basic threshold detection (improved)
        base_threshold = 40  # Lower but more accurate threshold with other detection methods
        if len(unique_ports) > (base_threshold * threshold_multiplier):
            scan_detected = True
            logging.warning(f"Port scan detected from {ip} - {len(unique_ports)} ports in {scan_window}s")
        
        # Method 2: Fast scan detection
        fast_scan_threshold = 15
        if len(recent_ports) > fast_scan_threshold:
            scan_detected = True
            logging.warning(f"Fast port scan detected from {ip} - {len(recent_ports)} ports in {short_window}s")
            
        # Method 3: Sequential port scanning
        if len(unique_ports) >= 5:
            port_list = sorted([int(p) for p in unique_ports if p.isdigit()])
            if len(port_list) >= 5:
                # Check for sequential port access
                sequence_count = 0
                for i in range(1, len(port_list)):
                    if port_list[i] == port_list[i-1] + 1:
                        sequence_count += 1
                        if sequence_count >= 4:  # 5 sequential ports
                            scan_detected = True
                            logging.warning(f"Sequential port scan detected from {ip}")
                            break
                    else:
                        sequence_count = 0
        
        # Method 4: Specific scan type detection
        if len(tcp_syn_ports) >= 10:
            scan_detected = True
            logging.warning(f"SYN scan detected from {ip} - {len(tcp_syn_ports)} SYN packets")
        if len(tcp_fin_ports) >= 8:
            scan_detected = True
            logging.warning(f"FIN scan detected from {ip} - {len(tcp_fin_ports)} FIN packets")
        if len(tcp_null_ports) >= 8:
            scan_detected = True
            logging.warning(f"NULL scan detected from {ip} - {len(tcp_null_ports)} NULL packets")
        if len(tcp_xmas_ports) >= 8:
            scan_detected = True
            logging.warning(f"XMAS scan detected from {ip} - {len(tcp_xmas_ports)} XMAS packets")
        
        # Update detection count if scan is detected
        if scan_detected and ip in self.port_scan_tracker:
            self.port_scan_tracker[ip]['scan_detection_count'] += 1
            
        return scan_detected

    def check_dns_amplification(self, packet):
        """Advanced DNS amplification attack detection"""
        # Check for DNS response (UDP port 53)
        if UDP in packet:
            src_port = packet[UDP].sport
            dst_port = packet[UDP].dport
            packet_len = len(packet)
            
            # Initialize DNS amplification tracker if not exists
            if not hasattr(self, 'dns_tracker'):
                self.dns_tracker = {}
            
            # Track source IP
            ip_src = packet[IP].src
            current_time = time.time()
            
            # Case 1: Check for large DNS responses (more severe)
            if src_port == 53:  # DNS server response
                # Store large DNS responses from this source
                if packet_len > 512:  # DNS responses over 512 bytes are suspicious
                    if ip_src not in self.dns_tracker:
                        self.dns_tracker[ip_src] = {
                            'large_responses': 1,
                            'last_update': current_time,
                            'max_size': packet_len,
                            'avg_size': packet_len,
                            'response_count': 1
                        }
                    else:
                        # Update tracker with new information
                        self.dns_tracker[ip_src]['large_responses'] += 1
                        self.dns_tracker[ip_src]['last_update'] = current_time
                        self.dns_tracker[ip_src]['response_count'] += 1
                        
                        # Update max size
                        if packet_len > self.dns_tracker[ip_src]['max_size']:
                            self.dns_tracker[ip_src]['max_size'] = packet_len
                            
                        # Update average size
                        avg = self.dns_tracker[ip_src]['avg_size']
                        count = self.dns_tracker[ip_src]['response_count']
                        self.dns_tracker[ip_src]['avg_size'] = avg + (packet_len - avg) / count
                    
                    # Check amplification patterns
                    if self.dns_tracker[ip_src]['large_responses'] > 5:
                        # Multiple large responses in a short time
                        if current_time - self.dns_tracker[ip_src]['last_update'] < 10:
                            logging.warning(f"DNS amplification attack detected from {ip_src}. Multiple large responses in short time.")
                            return True
                        # Very large responses (over 4000 bytes)
                        if self.dns_tracker[ip_src]['max_size'] > 4000:
                            logging.warning(f"DNS amplification attack detected from {ip_src}. Very large DNS response: {self.dns_tracker[ip_src]['max_size']} bytes")
                            return True
                        # High average response size
                        if self.dns_tracker[ip_src]['avg_size'] > 2000:
                            logging.warning(f"DNS amplification attack detected from {ip_src}. High average response size: {int(self.dns_tracker[ip_src]['avg_size'])} bytes")
                            return True
                
            # Case 2: Check for DNS queries that could be used in amplification
            elif dst_port == 53:  # DNS query
                # Look for specific query types known for amplification
                if DNS in packet:
                    try:
                        qtype = packet[DNS].qd.qtype
                        # Check for query types commonly used in amplification attacks
                        if qtype in [15, 16, 255, 46]:  # MX, TXT, ANY, RRSIG records
                            # Track query by IP to detect query patterns
                            if ip_src not in self.dns_tracker:
                                self.dns_tracker[ip_src] = {
                                    'risky_queries': 1,
                                    'last_query': current_time,
                                    'query_types': {qtype: 1}
                                }
                            else:
                                self.dns_tracker[ip_src]['risky_queries'] = self.dns_tracker[ip_src].get('risky_queries', 0) + 1
                                self.dns_tracker[ip_src]['last_query'] = current_time
                                if 'query_types' not in self.dns_tracker[ip_src]:
                                    self.dns_tracker[ip_src]['query_types'] = {}
                                self.dns_tracker[ip_src]['query_types'][qtype] = self.dns_tracker[ip_src]['query_types'].get(qtype, 0) + 1
                            
                            # Detect if there's a high rate of risky queries
                            if self.dns_tracker[ip_src]['risky_queries'] > 10:
                                logging.warning(f"Potential DNS amplification attack detected from {ip_src}. Multiple high-risk queries.")
                                return True
                    except:
                        pass  # Sometimes DNS parsing can fail
        
        return False

    def check_fragment_attack(self, packet):
        """Advanced fragment attack detection"""
        if IP in packet:
            # Initialize fragment tracking if not exists
            if not hasattr(self, 'frag_tracker'):
                self.frag_tracker = {}
                
            # Get source IP and packet info
            ip_src = packet[IP].src
            ip_id = packet[IP].id
            frag = packet[IP].frag
            flags = packet[IP].flags
            pkt_len = len(packet)
            has_more_fragments = (flags & 1)  # MF flag
            current_time = time.time()
            
            # Create a fragment tracking key
            frag_key = f"{ip_src}_{ip_id}"
            
            # Attack pattern 1: Tiny fragment attack
            # Fragments smaller than 576 bytes (except the last one) are suspicious
            if has_more_fragments and pkt_len < 200:
                logging.warning(f"Tiny fragment detected from {ip_src}, ID: {ip_id}, length: {pkt_len}")
                return True
            
            # Track fragment info
            if frag_key not in self.frag_tracker:
                self.frag_tracker[frag_key] = {
                    'first_seen': current_time,
                    'fragments': {frag: {'offset': frag * 8, 'size': pkt_len, 'mf': has_more_fragments}},
                    'total_size': pkt_len,
                    'max_offset': frag * 8 + pkt_len,
                    'complete': not has_more_fragments and frag == 0
                }
            else:
                # Update tracker
                self.frag_tracker[frag_key]['fragments'][frag] = {
                    'offset': frag * 8, 
                    'size': pkt_len, 
                    'mf': has_more_fragments
                }
                self.frag_tracker[frag_key]['total_size'] += pkt_len
                
                # Update max offset
                max_offset = frag * 8 + pkt_len
                if max_offset > self.frag_tracker[frag_key]['max_offset']:
                    self.frag_tracker[frag_key]['max_offset'] = max_offset
                
                # Mark as complete if we received a fragment with MF=0 (last fragment)
                if not has_more_fragments:
                    self.frag_tracker[frag_key]['complete'] = True
                
                # Attack pattern 2: Fragment Overlap Attack
                # Check for overlapping fragments
                fragments = self.frag_tracker[frag_key]['fragments']
                for other_frag, info in fragments.items():
                    if other_frag != frag:  # Don't compare with self
                        other_start = info['offset']
                        other_end = other_start + info['size']
                        current_start = frag * 8
                        current_end = current_start + pkt_len
                        
                        # Check for overlap
                        if (current_start < other_end and current_end > other_start):
                            logging.warning(f"Fragment overlap attack detected from {ip_src}, ID: {ip_id}")
                            return True
                
                # Attack pattern 3: Fragment Flood
                # Too many fragments for a single packet
                if len(fragments) > 64:  # Typical max fragments should be much lower
                    logging.warning(f"Excessive fragments detected from {ip_src}, ID: {ip_id}, count: {len(fragments)}")
                    return True
                
                # Attack pattern 4: Timeout Attack
                # Incomplete fragments persisting for too long
                if not self.frag_tracker[frag_key].get('complete', False):
                    if current_time - self.frag_tracker[frag_key]['first_seen'] > 30:  # 30 sec timeout
                        logging.warning(f"Fragment timeout attack detected from {ip_src}, ID: {ip_id}")
                        return True
                
                # Attack pattern 5: Jumbo Fragment
                # Check for unreasonably large total size
                if self.frag_tracker[frag_key]['total_size'] > 65535:  # Max IP packet
                    logging.warning(f"Jumbo fragment attack detected from {ip_src}, ID: {ip_id}, size: {self.frag_tracker[frag_key]['total_size']}")
                    return True
                
            # Clean up old fragment trackers (do this occasionally)
            if hasattr(self, 'last_frag_cleanup') and current_time - getattr(self, 'last_frag_cleanup', 0) > 60:  # Every minute
                self.last_frag_cleanup = current_time
                expired_keys = []
                for key, data in self.frag_tracker.items():
                    if current_time - data['first_seen'] > 120:  # 2 minutes
                        expired_keys.append(key)
                
                for key in expired_keys:
                    del self.frag_tracker[key]
                
                logging.debug(f"Cleaned up {len(expired_keys)} expired fragment trackers")
                    
        return False

    def check_malformed_packet(self, packet):
        """Advanced malformed (corrupted/tampered) packet detection"""
        try:
            # Basic header checks
            if IP in packet:
                # Check for invalid IP header length
                if packet[IP].ihl * 4 > len(packet[IP]):
                    logging.warning(f"Malformed packet detected: Invalid IP header length from {packet[IP].src}")
                    return True
                
                # Check for unreasonable header length
                if packet[IP].ihl < 5 or packet[IP].ihl > 15:  # Valid IP header length is 5-15
                    logging.warning(f"Malformed packet detected: Unreasonable IP header length from {packet[IP].src}")
                    return True
                
                # Check for invalid IP length
                if packet[IP].len > len(packet):
                    logging.warning(f"Malformed packet detected: IP length mismatch from {packet[IP].src}")
                    return True
                
                # Check for invalid IP version
                if packet[IP].version != 4:
                    logging.warning(f"Malformed packet detected: Invalid IP version {packet[IP].version} from {packet[IP].src}")
                    return True
                    
                # Check for invalid IP flags
                if packet[IP].flags > 7:  # 3 bits only
                    logging.warning(f"Malformed packet detected: Invalid IP flags from {packet[IP].src}")
                    return True
                
                # TCP checks
                if TCP in packet:
                    # Check for invalid TCP header length
                    if packet[TCP].dataofs * 4 > len(packet[TCP]):
                        logging.warning(f"Malformed packet detected: Invalid TCP header length from {packet[IP].src}")
                        return True
                        
                    # Check for invalid TCP flags - some tools use invalid combination of flags
                    tcp_flags = packet[TCP].flags
                    # Check for all flags set (XMAS scan) or other suspicious combos
                    if tcp_flags == 0xFF or (tcp_flags & 0x17) == 0x17:  # FIN+PSH+URG set
                        logging.warning(f"Malformed packet detected: Suspicious TCP flags combination from {packet[IP].src}")
                        return True
                        
                    # Check for SYN+FIN (mutually exclusive)
                    if (tcp_flags & 0x03) == 0x03:  # SYN+FIN
                        logging.warning(f"Malformed packet detected: SYN+FIN flags from {packet[IP].src}")
                        return True
                        
                    # Check for invalid TCP options
                    if len(packet[TCP].options) > 40:
                        logging.warning(f"Malformed packet detected: Excessive TCP options from {packet[IP].src}")
                        return True
                    
                    # Check for invalid TCP sequence/ack numbers (potential DOS)
                    if packet[TCP].seq == 0 and packet[TCP].ack == 0 and tcp_flags != 0x02:  # Not just a SYN
                        logging.warning(f"Malformed packet detected: Zero seq/ack from {packet[IP].src}")
                        return True
                
                # UDP checks
                if UDP in packet:
                    # Check for invalid UDP length
                    if packet[UDP].len > len(packet[UDP]) or packet[UDP].len < 8:  # UDP header is 8 bytes
                        logging.warning(f"Malformed packet detected: Invalid UDP length from {packet[IP].src}")
                        return True
                    
                    # Check for NULL UDP checksum (often used in attacks)
                    if packet[UDP].chksum == 0 and not (packet[IP].src.startswith('127.') or packet[IP].dst.startswith('127.')):
                        logging.warning(f"Malformed packet detected: NULL UDP checksum from {packet[IP].src}")
                        return True
                
                # Fragment checks - fragment attacks
                if packet[IP].flags & 0x1 or packet[IP].frag > 0:  # More fragments or non-zero offset
                    # Track fragments to detect fragment attacks
                    frag_key = f"{packet[IP].id}_{packet[IP].src}_{packet[IP].dst}"
                    
                    # Check for tiny fragments
                    if len(packet[IP].payload) < 16:  # Extremely small fragments
                        logging.warning(f"Malformed packet detected: Tiny fragment from {packet[IP].src}")
                        return True
        except Exception as e:
            # Any error in parsing usually indicates malformed packet
            logging.warning(f"Exception in packet analysis, likely malformed: {str(e)}")
            return True
            
        return False

    def check_ip_spoofing(self, packet):
        """Advanced IP spoofing detection"""
        if not IP in packet:
            return False
            
        src_ip = packet[IP].src
        dst_ip = packet[IP].dst
        pkt_ttl = packet[IP].ttl
        current_time = time.time()
        
        # Initialize spoofing detection trackers if they don't exist
        if not hasattr(self, 'spoofing_tracker'):
            self.spoofing_tracker = {}
            self.src_consistency = {}
            self.reserved_ips = [
                '0.0.0.0/8', '10.0.0.0/8', '100.64.0.0/10', '127.0.0.0/8',
                '169.254.0.0/16', '172.16.0.0/12', '192.0.0.0/24', '192.0.2.0/24',
                '192.88.99.0/24', '192.168.0.0/16', '198.18.0.0/15', 
                '198.51.100.0/24', '203.0.113.0/24', '224.0.0.0/4',
                '240.0.0.0/4', '255.255.255.255/32'
            ]
            self.reserved_ip_networks = [ipaddress.ip_network(net) for net in self.reserved_ips]
            
        # Attack Pattern 1: Invalid Source IPs
        # Check for invalid source IPs such as broadcast, multicast, reserved addresses
        try:
            ip_obj = ipaddress.ip_address(src_ip)
            if ip_obj.is_multicast or ip_obj.is_reserved or ip_obj.is_unspecified or ip_obj.is_loopback:
                logging.warning(f"Spoofed packet detected: Invalid source IP {src_ip} (reserved/special)")
                return True
                
            # Check if source IP is in a reserved or bogon address space
            for net in self.reserved_ip_networks:
                if ip_obj in net and not self.is_local_network(src_ip):
                    # Skip if it's a legitimate local network address
                    if not (self.is_local_network(src_ip) and self.interface in ['lo', 'lo0']):
                        logging.warning(f"Spoofed packet detected: Source IP {src_ip} is in reserved network {net}")
                        return True
        except:
            # Invalid IP format
            logging.warning(f"Spoofed packet detected: Invalid IP format {src_ip}")
            return True
            
        # Attack Pattern 2: Impossible IP combinations
        # Check for impossible source-destination combinations
        if src_ip == dst_ip and not src_ip.startswith('127.'):
            logging.warning(f"Spoofed packet detected: Source and destination IP are identical: {src_ip}")
            return True
            
        # Attack Pattern 3: TTL-based spoofing detection
        # Track typical TTL values per source IP
        if src_ip not in self.src_consistency:
            self.src_consistency[src_ip] = {
                'first_seen': current_time,
                'ttl_values': [pkt_ttl],
                'ttl_count': {pkt_ttl: 1},
                'mac_addresses': set(),
                'last_packet': current_time
            }
            # If we have MAC information, record it
            if Ether in packet:
                self.src_consistency[src_ip]['mac_addresses'].add(packet[Ether].src)
        else:
            # Update TTL tracking
            profile = self.src_consistency[src_ip]
            profile['ttl_values'].append(pkt_ttl)
            profile['last_packet'] = current_time
            
            # Keep only the last 20 TTL values to avoid memory bloat
            if len(profile['ttl_values']) > 20:
                profile['ttl_values'] = profile['ttl_values'][-20:]
                
            # Update TTL count
            if pkt_ttl in profile['ttl_count']:
                profile['ttl_count'][pkt_ttl] += 1
            else:
                profile['ttl_count'][pkt_ttl] = 1
                
            # If we have MAC information, record it
            if Ether in packet:
                profile['mac_addresses'].add(packet[Ether].src)
                
            # Check for TTL anomalies
            if len(profile['ttl_values']) >= 5:  # Need some history for comparison
                ttl_values = profile['ttl_values'][-5:]
                dominant_ttl = max(profile['ttl_count'], key=profile['ttl_count'].get)
                
                # Calculate standard deviation of TTL values
                avg_ttl = sum(ttl_values) / len(ttl_values)
                variance = sum((x - avg_ttl) ** 2 for x in ttl_values) / len(ttl_values)
                std_dev = variance ** 0.5
                
                # Check for high TTL variance (which could indicate spoofing)
                # BUT exclude cases where TTL legitimately changes between OS updates
                if std_dev > 8 and len(profile['ttl_count']) > 3:
                    logging.warning(f"Spoofed packet detected: Highly variable TTL from {src_ip}, std dev: {std_dev:.2f}")
                    return True
                    
        # Attack Pattern 4: MAC-IP inconsistency
        # Check if a single IP address is coming from multiple MAC addresses
        # This typically shouldn't happen unless there's ARP spoofing or IP spoofing
        profile = self.src_consistency.get(src_ip, {})
        if profile and len(profile.get('mac_addresses', set())) > 3:
            logging.warning(f"Spoofed packet detected: IP {src_ip} seen with {len(profile['mac_addresses'])} different MAC addresses")
            return True
        
        # Attack Pattern 5: Local address from external interface
        # Private IPs shouldn't come from external interfaces
        if self.interface not in ['lo', 'lo0'] and not self.is_local_network(src_ip):
            try:
                ip_obj = ipaddress.ip_address(src_ip)
                if ip_obj.is_private:
                    logging.warning(f"Spoofed packet detected: Private IP {src_ip} from external interface")
                    return True
            except:
                pass
            
        # Clean up old entries every 10 minutes
        if hasattr(self, 'last_spoofing_cleanup') and current_time - getattr(self, 'last_spoofing_cleanup', 0) > 600:
            self.last_spoofing_cleanup = current_time
            expired_keys = []
            for key, data in self.src_consistency.items():
                if current_time - data['last_packet'] > 3600:  # 1 hour
                    expired_keys.append(key)
                    
            for key in expired_keys:
                del self.src_consistency[key]
                
            logging.debug(f"Cleaned up {len(expired_keys)} expired IP spoofing tracking entries")
        
        return False

    def check_ttl_anomalies(self, packet):
        """Enhanced detection of TTL anomalies"""
        if IP in packet:
            ttl = packet[IP].ttl
            ip_src = packet[IP].src
            
            # Normal TTL ranges by OS
            # Windows: Usually 128 or 64
            # Linux/Unix: Usually 64
            # Network equipment (routers): Usually 255
            
            # Track TTL values by IP to detect inconsistencies
            if ip_src not in self.ttl_tracker:
                self.ttl_tracker[ip_src] = {'values': [ttl], 'last_update': time.time()}
            else:
                self.ttl_tracker[ip_src]['values'].append(ttl)
                self.ttl_tracker[ip_src]['last_update'] = time.time()
                
                # Keep only the last 10 values
                if len(self.ttl_tracker[ip_src]['values']) > 10:
                    self.ttl_tracker[ip_src]['values'] = self.ttl_tracker[ip_src]['values'][-10:]
                
                # Check for TTL inconsistency within the same IP
                ttl_values = self.ttl_tracker[ip_src]['values']
                if len(ttl_values) > 3:  # Only check if we have enough samples
                    # Calculate the standard deviation of TTL values
                    avg = sum(ttl_values) / len(ttl_values)
                    variance = sum((x - avg) ** 2 for x in ttl_values) / len(ttl_values)
                    std_dev = variance ** 0.5
                    
                    # Significant TTL variations may indicate IP spoofing or TTL manipulation
                    if std_dev > 5 and max(ttl_values) - min(ttl_values) > 10:
                        logging.warning(f"TTL anomaly detected from {ip_src}: inconsistent TTL values {ttl_values}")
                        return True
            
            # Detect extremely low or high TTL values
            if ttl < 5 or ttl > 250:
                return True
                
        return False

    def check_tcp_sequence_prediction(self, packet):
        """Enhanced check for TCP sequence prediction attacks"""
        if TCP in packet:
            seq = packet[TCP].seq
            ip_src = packet[IP].src
            
            # Using lock to prevent race conditions on sequence tracking
            with self.tcp_flags_lock:
                # Initialize sequence tracker for this IP if it doesn't exist
                if not hasattr(self, 'seq_tracker'):
                    self.seq_tracker = {}
                    
                if ip_src not in self.seq_tracker:
                    self.seq_tracker[ip_src] = {
                        'sequences': [seq],
                        'last_update': time.time(),
                        'prediction_attempts': 0
                    }
                else:
                    # Add new sequence
                    self.seq_tracker[ip_src]['sequences'].append(seq)
                    self.seq_tracker[ip_src]['last_update'] = time.time()
                    
                    # Keep only the most recent sequences (limited to 8)
                    if len(self.seq_tracker[ip_src]['sequences']) > 8:
                        self.seq_tracker[ip_src]['sequences'] = self.seq_tracker[ip_src]['sequences'][-8:]
                    
                    # Check for predictable sequence patterns
                    sequences = self.seq_tracker[ip_src]['sequences']
                    if len(sequences) >= 3:
                        # Check for linear progression
                        diffs = [sequences[i+1] - sequences[i] for i in range(len(sequences)-1)]
                        
                        # If we have consistent differences (potential linear sequence pattern)
                        if len(set(diffs)) <= 2 and len(diffs) >= 3:
                            self.seq_tracker[ip_src]['prediction_attempts'] += 1
                            logging.warning(f"Potential TCP sequence prediction attack from {ip_src}")
                            return True
                        
                        # Check for simple incremental patterns (like seq+1)
                        if all(d == 1 for d in diffs):
                            self.seq_tracker[ip_src]['prediction_attempts'] += 1
                            logging.warning(f"Simple TCP sequence pattern detected from {ip_src}")
                            return True
                        
                        # Check for numerically close patterns
                        if all(0 < d < 100 for d in diffs):
                            self.seq_tracker[ip_src]['prediction_attempts'] += 1
                            logging.warning(f"Suspicious TCP sequence proximity from {ip_src}")
                            return True
                
                # Basic checks for obviously bad sequences
                if seq == 0 or seq == 1:
                    return True
                
        return False

    def cleanup_old_data(self):
        """Clean up old tracking data to prevent memory leaks and reduce resource usage"""
        try:
            current_time = time.time()
            cutoff_time = current_time - 3600  # Remove data older than 1 hour
            
            # Define maximum sizes for OrderedDict tracking structures to prevent unbounded growth
            # This is critical for preventing memory issues during extended operation
            max_entries = 5000  # Maximum entries to keep in tracking dictionaries
            
            # Using locks to ensure thread safety during cleanup
            with self.stats_lock:
                # Clean and limit syn_tracker dictionary
                if hasattr(self, 'syn_tracker'):
                    # Remove old entries first
                    for ip in list(self.syn_tracker.keys()):
                        if 'timestamp' in self.syn_tracker[ip] and self.syn_tracker[ip]['timestamp'] < cutoff_time:
                            del self.syn_tracker[ip]
                    # Then enforce size limit by removing oldest entries
                    while len(self.syn_tracker) > max_entries:
                        self.syn_tracker.popitem(last=False)  # Remove oldest entry (FIFO)
                
                # Clean and limit udp_tracker dictionary
                if hasattr(self, 'udp_tracker'):
                    for ip in list(self.udp_tracker.keys()):
                        if 'timestamp' in self.udp_tracker[ip] and self.udp_tracker[ip]['timestamp'] < cutoff_time:
                            del self.udp_tracker[ip]
                    while len(self.udp_tracker) > max_entries:
                        self.udp_tracker.popitem(last=False)
                
                # Clean and limit icmp_tracker
                if hasattr(self, 'icmp_tracker'):
                    for ip in list(self.icmp_tracker.keys()):
                        if 'timestamp' in self.icmp_tracker[ip] and self.icmp_tracker[ip]['timestamp'] < cutoff_time:
                            del self.icmp_tracker[ip]
                    while len(self.icmp_tracker) > max_entries:
                        self.icmp_tracker.popitem(last=False)
                
                # Clean and limit port_scan_tracker
                if hasattr(self, 'port_scan_tracker'):
                    for ip in list(self.port_scan_tracker.keys()):
                        if 'timestamp' in self.port_scan_tracker[ip] and self.port_scan_tracker[ip]['timestamp'] < cutoff_time:
                            del self.port_scan_tracker[ip]  
                    while len(self.port_scan_tracker) > max_entries:
                        self.port_scan_tracker.popitem(last=False)
            
            # Using tcp_flags_lock for these specific structures
            with self.tcp_flags_lock:
                # Clean and limit tcp_flags_tracker
                if hasattr(self, 'tcp_flags_tracker'):
                    for ip in list(self.tcp_flags_tracker.keys()):
                        if 'timestamp' in self.tcp_flags_tracker[ip] and self.tcp_flags_tracker[ip]['timestamp'] < cutoff_time:
                            del self.tcp_flags_tracker[ip]
                    while len(self.tcp_flags_tracker) > max_entries:
                        self.tcp_flags_tracker.popitem(last=False)
                
                # Clean and limit seq_tracker
                if hasattr(self, 'seq_tracker'):
                    for ip in list(self.seq_tracker.keys()):
                        if 'timestamp' in self.seq_tracker[ip] and self.seq_tracker[ip]['timestamp'] < cutoff_time:
                            del self.seq_tracker[ip]
                    while len(self.seq_tracker) > max_entries:
                        self.seq_tracker.popitem(last=False)
            
            # Clean fragment tracker with its own lock
            with self.fragment_lock:
                if hasattr(self, 'fragment_tracker'):
                    for ip in list(self.fragment_tracker.keys()):
                        if 'timestamp' in self.fragment_tracker[ip] and self.fragment_tracker[ip]['timestamp'] < cutoff_time:
                            del self.fragment_tracker[ip]
                    while len(self.fragment_tracker) > max_entries:
                        self.fragment_tracker.popitem(last=False)
            
            # Clean attack_sources to prevent unbounded growth
            if hasattr(self, 'attack_sources'):
                # For attack sources, use a longer retention (4 hours) but also limit size
                attack_cutoff = current_time - 14400  # 4 hours
                attack_max_entries = 10000  # More entries for attack history
                
                for ip in list(self.attack_sources.keys()):
                    if 'last_attack' in self.attack_sources[ip] and self.attack_sources[ip]['last_attack'] < attack_cutoff:
                        # If IP is blocked, don't remove it from history
                        if not self.attack_sources[ip].get('blocked', False):
                            del self.attack_sources[ip]
                
                # If still too large, remove oldest based on first_attack time
                if len(self.attack_sources) > attack_max_entries:
                    # Sort by first_attack time and keep only the newest entries
                    sorted_entries = sorted(self.attack_sources.items(), 
                                           key=lambda x: x[1].get('first_attack', 0))
                    to_remove = sorted_entries[:len(sorted_entries) - attack_max_entries]
                    for ip, _ in to_remove:
                        if not self.attack_sources[ip].get('blocked', False):
                            del self.attack_sources[ip]
            
            # Log memory usage statistics periodically
            logging.info(f"Memory cleanup performed: {len(self.syn_tracker) if hasattr(self, 'syn_tracker') else 0} SYN entries, "
                        f"{len(self.udp_tracker) if hasattr(self, 'udp_tracker') else 0} UDP entries")
                
        except Exception as e:
            logging.error(f"Error in cleanup_old_data: {str(e)}")
            # Continue operation despite cleanup errors
    
    def block_ip(self, ip, reason="Attack detected"):
        """Block an IP address"""
        if ip in self.local_ips:
            logging.warning(f"Attempt to block local IP {ip} prevented")
            return False
            
        if self.is_ip_in_whitelist(ip):
            logging.warning(f"Attempt to block whitelisted IP: {ip} - Reason: {reason}")
            return False
        
        if ip not in self.blocked_ips:
            self.blocked_ips[ip] = {
                'timestamp': time.time(),
                'reason': reason
            }
            try:
                # Add blocking rule
                result = subprocess.run(
                    ['iptables', '-A', 'INPUT', '-s', ip, '-j', 'DROP'],
                    capture_output=True, text=True, check=True
                )
                logging.info(f"Blocked IP: {ip} - Reason: {reason}")
                
                # If IP is not in blacklist and should be permanently blocked
                if reason in ["Blacklisted", "Reputation based block"] and ip not in self.blacklist:
                    self.blacklist.append(ip)
                    self.save_ip_lists()
                return True
            except subprocess.CalledProcessError as e:
                logging.error(f"Failed to block IP {ip}: {e.stderr}")
                return False
            except Exception as e:
                logging.error(f"Error blocking IP {ip}: {str(e)}")
                return False
        return True

    def start_protection(self):
        if not self.interface:
            print(f"{Fore.RED}Error: No network interface selected!{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}Please select a network interface first (Option 8).{Style.RESET_ALL}")
            input("\nPress Enter to return to main menu...")
            return False

        if not self.is_running:
            try:
                # Check if interface exists and is up
                interfaces = self.get_available_interfaces()
                interface_exists = False
                for iface in interfaces:
                    if iface['name'] == self.interface:
                        interface_exists = True
                        if iface['status'] != 'UP':
                            print(f"{Fore.RED}Error: Interface {self.interface} is DOWN!{Style.RESET_ALL}")
                            return False
                        break
                
                if not interface_exists:
                    print(f"{Fore.RED}Error: Interface {self.interface} not found!{Style.RESET_ALL}")
                    return False

                # If auto updates are enabled and it's time to check for updates
                if self.auto_update and time.time() - self.last_update_check > self.update_interval:
                    print(f"{Fore.YELLOW}Checking for updates...{Style.RESET_ALL}")
                    self.check_for_updates()

                self.is_running = True
                # Save start time
                self.start_time = time.time()
                
                # Clear screen and show startup banner
                os.system('clear')
                print(self.get_ascii_art())
                print(f"\n{Fore.GREEN}[+] Starting OpenMammoth Protection System{Style.RESET_ALL}")
                print(f"{Fore.CYAN}[*] Interface: {self.interface}{Style.RESET_ALL}")
                print(f"{Fore.CYAN}[*] Protection Level: {self.protection_level}{Style.RESET_ALL}")
                print(f"{Fore.CYAN}[*] Advanced Protection: {'Enabled' if self.advanced_protection else 'Disabled'}{Style.RESET_ALL}")
                print(f"{Fore.CYAN}[*] Threat Intelligence: {'Enabled' if self.use_threat_intel else 'Disabled'}{Style.RESET_ALL}")
                print(f"\n{Fore.YELLOW}[*] Initializing protection modules...{Style.RESET_ALL}")
                
                def packet_capture():
                    try:
                        print(f"{Fore.GREEN}[+] Starting packet capture on {self.interface}...{Style.RESET_ALL}")
                        # Set Scapy logging level to reduce noise
                        logging.getLogger("scapy.runtime").setLevel(logging.ERROR)
                        
                        # Try to create L3 socket with appropriate privileges
                        conf.L3socket = L3RawSocket
                        
                        print(f"{Fore.GREEN}[+] Packet capture initialized successfully{Style.RESET_ALL}")
                        print(f"{Fore.GREEN}[+] Protection system is now active{Style.RESET_ALL}")
                        print(f"\n{Fore.CYAN}[*] Monitoring network traffic...{Style.RESET_ALL}")
                        
                        # Start sniffing with store=0 to avoid memory issues
                        sniff(iface=self.interface, 
                              prn=self.packet_handler, 
                              store=0,
                              filter="ip",  # Only capture IP packets
                              stop_filter=lambda p: not self.is_running)
                              
                    except PermissionError:
                        logging.error("Permission denied when starting packet capture. Make sure you're running as root.")
                        print(f"{Fore.RED}Error: Permission denied. Make sure you're running as root.{Style.RESET_ALL}")
                        self.is_running = False
                    except Exception as e:
                        logging.error(f"Error in packet capture: {str(e)}")
                        print(f"{Fore.RED}Error in packet capture: {str(e)}{Style.RESET_ALL}")
                        self.is_running = False
                
                def data_cleanup():
                    while self.is_running:
                        try:
                            self.cleanup_old_data()
                            time.sleep(self.cleanup_interval)
                        except Exception as e:
                            logging.error(f"Error in data cleanup: {str(e)}")
                
                def auto_updater():
                    while self.is_running and self.auto_update:
                        try:
                            if time.time() - self.last_update_check > self.update_interval:
                                logging.info("Running scheduled threat intelligence update")
                                self.update_threat_intel()
                            time.sleep(3600)  # Wait for 1 hour
                        except Exception as e:
                            logging.error(f"Error in auto updater: {str(e)}")
                
                # Start packet capture thread
                self.capture_thread = threading.Thread(target=packet_capture)
                self.capture_thread.daemon = True
                self.capture_thread.start()
                
                # Start cleanup thread
                self.cleanup_thread = threading.Thread(target=data_cleanup)
                self.cleanup_thread.daemon = True
                self.cleanup_thread.start()
                
                # Start update thread
                self.update_thread = threading.Thread(target=auto_updater)
                self.update_thread.daemon = True
                self.update_thread.start()
                
                # Wait a moment to see if packet capture starts successfully
                time.sleep(2)
                if not self.is_running:
                    print(f"{Fore.RED}Failed to start protection. Check the logs for details.{Style.RESET_ALL}")
                    return False
                
                print(f"{Fore.GREEN}Protection started successfully on {self.interface}{Style.RESET_ALL}")
                logging.info(f"Protection started on interface {self.interface}")
                return True
                
            except Exception as e:
                print(f"{Fore.RED}Error starting protection: {str(e)}{Style.RESET_ALL}")
                logging.error(f"Error starting protection: {str(e)}")
                self.is_running = False
                return False
        return False

    def _setup_signal_handlers(self):
        """Set up signal handlers for graceful shutdown"""
        try:
            import signal
            
            # Define the signal handler for SIGINT (Ctrl+C) and SIGTERM
            def signal_handler(sig, frame):
                print(f"\n{Fore.YELLOW}Signal {sig} received. Shutting down gracefully...{Style.RESET_ALL}")
                logging.info(f"Signal {sig} received. Shutting down gracefully...")
                self.stop_protection()
                sys.exit(0)
            
            # Register the signal handlers
            signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
            signal.signal(signal.SIGTERM, signal_handler)  # Termination signal
            
            # On Unix systems, handle SIGHUP as well
            if hasattr(signal, 'SIGHUP'):
                signal.signal(signal.SIGHUP, signal_handler)  # Terminal closed
                
            logging.info("Signal handlers registered successfully")
        except Exception as e:
            logging.error(f"Error setting up signal handlers: {str(e)}")
            print(f"{Fore.RED}Warning: Could not set up signal handlers: {str(e)}{Style.RESET_ALL}")
            
    def stop_protection(self):
        """Stop packet capture and all monitoring threads"""
        if self.is_running:
            self.is_running = False
            print(f"{Fore.YELLOW}Stopping protection...{Style.RESET_ALL}")
            
            # Close sniffer and wait for threads to finish
            if hasattr(self, 'capture_thread') and self.capture_thread and self.capture_thread.is_alive():
                try:
                    if hasattr(self, 'sniffer'):
                        try:
                            self.sniffer.stop()
                        except Exception as e:
                            logging.error(f"Error stopping sniffer: {str(e)}")
                    self.capture_thread.join(5)
                except Exception as e:
                    logging.error(f"Error stopping capture thread: {str(e)}")
            
            # Ensure thread pool is properly shut down
            if hasattr(self, 'thread_pool'):
                try:
                    self.thread_pool.shutdown(wait=True)  # Wait for all tasks to complete
                    logging.info("Thread pool shutdown successfully")
                except Exception as e:
                    logging.error(f"Error shutting down thread pool: {str(e)}")
            
            # Wait for other threads
            if self.cleanup_thread and self.cleanup_thread.is_alive():
                try:
                    self.cleanup_thread.join(5)
                except Exception as e:
                    logging.error(f"Error stopping cleanup thread: {str(e)}")
            
            if self.update_thread and self.update_thread.is_alive():
                try:
                    self.update_thread.join(5)
                except Exception as e:
                    logging.error(f"Error stopping update thread: {str(e)}")
            
            # Properly shutdown thread pool executor with a timeout
            if hasattr(self, 'thread_pool'):
                try:
                    logging.info("Shutting down thread pool...")
      
                    if sys.version_info >= (3, 9):
                        self.thread_pool.shutdown(wait=True, cancel_futures=True)
                    else:
                        self.thread_pool.shutdown(wait=True)
                    logging.info("Thread pool shutdown complete")
                except Exception as pool_err:
                    logging.error(f"Error shutting down thread pool: {str(pool_err)}")
            
            # Cleanup iptables rules, but only for temporary blocks (not blacklisted)
            for ip in list(self.blocked_ips.keys()):
                if ip not in self.blacklist:  # Keep blocking IPs in the blacklist
                    try:
                        subprocess.run(
                            ['iptables', '-D', 'INPUT', '-s', ip, '-j', 'DROP'],
                            capture_output=True, text=True, check=True
                        )
                        del self.blocked_ips[ip]
                    except Exception as e:
                        logging.error(f"Error removing iptables rule for {ip}: {str(e)}")
            
            # Clean up resources
            try:
                # Scapy sockets might still be open
                conf.L2socket = None
                conf.L3socket = None
            except Exception as e:
                logging.error(f"Error cleaning up sockets: {str(e)}")
            
            logging.info("Protection stopped")
            return True
        return False

    def cleanup_old_data(self):
        """Clean up old data to reduce memory usage"""
        current_time = time.time()
        self.last_cleanup_time = current_time
        
        # Connection tracker cleanup
        expired_connections = []
        for key, data in self.connection_tracker.items():
            # Clean up connections older than 10 minutes
            if current_time - data['timestamp'] > 600:
                expired_connections.append(key)
        
        # Keep at most 1000 connection records
        if len(self.connection_tracker) > 1000:
            connection_items = sorted(self.connection_tracker.items(), 
                                      key=lambda x: x[1]['timestamp'])
            # List of oldest connections
            extra_connections = connection_items[:len(connection_items) - 1000]
            expired_connections.extend([k for k, v in extra_connections])
        
        # Clean up
        for key in expired_connections:
            if key in self.connection_tracker:
                del self.connection_tracker[key]
        
        # Packet rates cleanup
        expired_rates = []
        for ip, data in self.packet_rates.items():
            # Clean up data older than 2 minutes
            if current_time - data['timestamp'] > 120:
                expired_rates.append(ip)
        
        # Clean up
        for ip in expired_rates:
            if ip in self.packet_rates:
                del self.packet_rates[ip]
        
        # Log
        logging.info(f"Data cleanup completed - Removed {len(expired_connections)} connections and {len(expired_rates)} packet rates")

    def display_menu(self):
        while True:
            os.system('clear')
            print(self.get_ascii_art())
            print(f"\n{Fore.CYAN}=== OpenMammoth Network Protection ==={Style.RESET_ALL}")
            print(f"{Fore.GREEN}1. Start Protection{Style.RESET_ALL}")
            print(f"{Fore.RED}2. Stop Protection{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}3. Protection Status{Style.RESET_ALL}")
            print(f"{Fore.BLUE}4. Settings{Style.RESET_ALL}")
            print(f"{Fore.MAGENTA}5. View Statistics{Style.RESET_ALL}")
            print(f"{Fore.CYAN}6. View Blocked IPs{Style.RESET_ALL}")
            print(f"{Fore.GREEN}7. Advanced Options{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}8. Configure Network Interfaces{Style.RESET_ALL}")
            print(f"{Fore.CYAN}9. Help{Style.RESET_ALL}")
            print(f"{Fore.CYAN}10. About{Style.RESET_ALL}")
            print(f"{Fore.RED}0. Exit{Style.RESET_ALL}")
            
            choice = input("\nEnter your choice (0-10): ")
            
            if choice == "1":
                self.start_protection()
            elif choice == "2":
                self.stop_protection()
            elif choice == "3":
                self.view_protection_status()
            elif choice == "4":
                self.settings_menu()
            elif choice == "5":
                self.view_statistics()
            elif choice == "6":
                self.view_blocked_ips()
            elif choice == "7":
                self.advanced_options()
            elif choice == "8":
                self.configure_interfaces()
            elif choice == "9":
                self.show_help()
            elif choice == "10":
                self.show_about()
            elif choice == "0":
                if self.is_running:
                    self.stop_protection()
                print(f"{Fore.GREEN}Goodbye!{Style.RESET_ALL}")
                break
            else:
                print(f"{Fore.RED}Invalid choice. Please try again.{Style.RESET_ALL}")

    def settings_menu(self):
        while True:
            print(f"\n{Fore.CYAN}=== Settings ==={Style.RESET_ALL}")
            print(f"1. Protection Level (Current: {self.protection_level})")
            print(f"2. Advanced Protection (Current: {'Enabled' if self.advanced_protection else 'Disabled'})")
            print(f"3. Debug Mode (Current: {'Enabled' if self.debug_mode else 'Disabled'})")
            print(f"4. Network Interface (Current: {self.interface if self.interface else 'Not selected'})")
            print(f"5. Threat Intelligence (Current: {'Enabled' if self.use_threat_intel else 'Disabled'})")
            print(f"6. Auto Updates (Current: {'Enabled' if self.auto_update else 'Disabled'})")
            print(f"7. Reset IPTables Rules")
            print("8. Back to Main Menu")
            
            choice = input("\nEnter your choice (1-8): ")
            
            if choice == "1":
                level = input("Enter protection level (1-4): ")
                if level.isdigit() and 1 <= int(level) <= 4:
                    self.protection_level = int(level)
                    self.save_config()
                    print(f"{Fore.GREEN}Protection level set to {self.protection_level}{Style.RESET_ALL}")
            elif choice == "2":
                self.advanced_protection = not self.advanced_protection
                self.save_config()
                status = "enabled" if self.advanced_protection else "disabled"
                print(f"{Fore.GREEN}Advanced protection {status}{Style.RESET_ALL}")
            elif choice == "3":
                self.debug_mode = not self.debug_mode
                self.setup_logging()
                self.save_config()
                status = "enabled" if self.debug_mode else "disabled"
                print(f"{Fore.GREEN}Debug mode {status}{Style.RESET_ALL}")
            elif choice == "4":
                if self.select_interface():
                    self.save_config()
            elif choice == "5":
                self.use_threat_intel = not self.use_threat_intel
                self.save_config()
                status = "enabled" if self.use_threat_intel else "disabled"
                print(f"{Fore.GREEN}Threat intelligence {status}{Style.RESET_ALL}")
                if self.use_threat_intel and (not self.threat_intel_db or time.time() - self.last_update_check > self.update_interval):
                    print(f"{Fore.YELLOW}Updating threat intelligence database...{Style.RESET_ALL}")
                    self.update_threat_intel()
            elif choice == "6":
                self.auto_update = not self.auto_update
                self.save_config()
                status = "enabled" if self.auto_update else "disabled"
                print(f"{Fore.GREEN}Auto updates {status}{Style.RESET_ALL}")
                if self.auto_update and time.time() - self.last_update_check > self.update_interval:
                    print(f"{Fore.YELLOW}Checking for updates...{Style.RESET_ALL}")
                    self.check_for_updates()
            elif choice == "7":
                self.reset_iptables_rules()
            elif choice == "8":
                break
            else:
                print(f"{Fore.RED}Invalid choice. Please try again.{Style.RESET_ALL}")

    def view_statistics(self):
        """Show protection statistics"""
        try:
            print(f"\n{Fore.CYAN}=== Protection Statistics ==={Style.RESET_ALL}")
            
            # Calculate uptime
            if hasattr(self, 'start_time') and self.is_running:
                uptime = time.time() - self.start_time
                hours, remainder = divmod(uptime, 3600)
                minutes, seconds = divmod(remainder, 60)
                print(f"Uptime: {int(hours)}h {int(minutes)}m {int(seconds)}s")
            
            print(f"Total Packets: {self.stats['total_packets']}")
            print(f"Blocked Packets: {self.stats['blocked_packets']}")
            print(f"Attacks Detected: {self.stats['attacks_detected']}")
            print(f"Port Scans: {self.stats['port_scans']}")
            print(f"SYN Floods: {self.stats['syn_floods']}")
            print(f"UDP Floods: {self.stats['udp_floods']}")
            print(f"ICMP Floods: {self.stats['icmp_floods']}")
            print(f"DNS Amplification: {self.stats['dns_amplification']}")
            print(f"Fragment Attacks: {self.stats['fragment_attacks']}")
            print(f"Malformed Packets: {self.stats['malformed_packets']}")
            print(f"Spoofed IPs: {self.stats['spoofed_ips']}")
            print(f"Threat Intel Blocks: {self.stats['threat_intel_blocks']}")
            print(f"Reputation Blocks: {self.stats['reputation_blocks']}")
            
            # Packet rates and active connections
            if self.is_running:
                print(f"\nActive connections: {len(self.connection_tracker)}")
                
            input("\nPress Enter to return to main menu...")
        except Exception as e:
            logging.error(f"Error displaying statistics: {str(e)}")
            print(f"{Fore.RED}Error displaying statistics: {str(e)}{Style.RESET_ALL}")

    def view_blocked_ips(self):
        """View blocked IP addresses"""
        os.system('clear')  # Clear screen first
        print(f"\n{Fore.CYAN}=== Blocked IP Addresses ==={Style.RESET_ALL}")
        
        if not self.blocked_ips:
            print(f"\n{Fore.YELLOW}No IPs are currently blocked.{Style.RESET_ALL}")
        else:
            print(f"\nTotal Blocked IPs: {len(self.blocked_ips)}\n")
            print(f"{Fore.CYAN}{'IP Address':<20} {'Duration':<15} {'Reason':<30}{Style.RESET_ALL}")
            print("-" * 65)
            
            current_time = time.time()
            for ip, info in self.blocked_ips.items():
                duration = current_time - info['timestamp']
                # Convert duration to human readable format
                if duration < 60:
                    duration_str = f"{int(duration)}s"
                elif duration < 3600:
                    duration_str = f"{int(duration/60)}m"
                else:
                    duration_str = f"{int(duration/3600)}h"
                
                print(f"{ip:<20} {duration_str:<15} {info['reason']:<30}")
        
        print("\nPress Enter to return to main menu...")
        input()

    def advanced_options(self):
        while True:
            print(f"\n{Fore.CYAN}=== Advanced Options ==={Style.RESET_ALL}")
            print("1. View Detailed Logs")
            print("2. Export Statistics")
            print("3. Clear Blocked IPs")
            print("4. Manage Whitelist")
            print("5. Manage Blacklist")
            print("6. Update Threat Intelligence")
            print("7. Firewall Settings")
            print("8. Back to Main Menu")
            
            choice = input("\nEnter your choice (1-8): ")
            
            if choice == "1":
                self.view_logs()
            elif choice == "2":
                self.export_statistics()
            elif choice == "3":
                self.clear_blocked_ips()
            elif choice == "4":
                self.manage_whitelist()
            elif choice == "5":
                self.manage_blacklist()
            elif choice == "6":
                self.update_threat_intel()
                print(f"{Fore.GREEN}Threat intelligence database updated.{Style.RESET_ALL}")
            elif choice == "7":
                self.firewall_settings()
            elif choice == "8":
                break
            else:
                print(f"{Fore.RED}Invalid choice. Please try again.{Style.RESET_ALL}")

    def view_logs(self):
        """View detailed logs"""
        os.system('clear')
        try:
            log_path = os.path.join(self.config_dir, 'openmammoth.log')
            if os.path.exists(log_path):
                print(f"\n{Fore.CYAN}=== Recent Logs ==={Style.RESET_ALL}")
                with open(log_path, 'r') as f:
                    logs = f.readlines()
                    # Show last 20 lines with proper formatting
                    for line in logs[-20:]:
                        # Color code different log levels
                        if "ERROR" in line:
                            print(f"{Fore.RED}{line.strip()}{Style.RESET_ALL}")
                        elif "WARNING" in line:
                            print(f"{Fore.YELLOW}{line.strip()}{Style.RESET_ALL}")
                        else:
                            print(line.strip())
            else:
                print(f"{Fore.RED}No log file found.{Style.RESET_ALL}")
        except Exception as e:
            print(f"{Fore.RED}Error reading log file: {str(e)}{Style.RESET_ALL}")
        
        input("\nPress Enter to return to Advanced Options...")

    def export_statistics(self):
        """Export statistics to a file"""
        try:
            os.system('clear')
            print(f"\n{Fore.CYAN}=== Export Statistics ==={Style.RESET_ALL}")
            
            # Create export data
            export_data = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "stats": self.stats,
                "configuration": {
                    "protection_level": self.protection_level,
                    "advanced_protection": self.advanced_protection,
                    "interface": self.interface,
                    "threat_intel_enabled": self.use_threat_intel
                },
                "blocked_ips": len(self.blocked_ips),
                "whitelisted_ips": len(self.whitelist),
                "blacklisted_ips": len(self.blacklist)
            }
            
            # Create filename with timestamp
            filename = f"openmammoth_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(filename, 'w') as f:
                json.dump(export_data, f, indent=4)
            
            print(f"\n{Fore.GREEN}[+] Statistics exported successfully to: {filename}{Style.RESET_ALL}")
        except Exception as e:
            print(f"{Fore.RED}Error exporting statistics: {str(e)}{Style.RESET_ALL}")
        
        input("\nPress Enter to return to Advanced Options...")

    def firewall_settings(self):
        """Manage firewall settings"""
        while True:
            os.system('clear')
            print(f"\n{Fore.CYAN}=== Firewall Settings ==={Style.RESET_ALL}")
            print("1. View Current Firewall Rules")
            print("2. Reset All Firewall Rules")
            print("3. Apply Basic Protection Rules")
            print("4. Back to Advanced Options")
            
            choice = input("\nEnter your choice (1-4): ")
            
            if choice == "1":
                self.view_firewall_rules()
            elif choice == "2":
                self.reset_iptables_rules()
            elif choice == "3":
                self.apply_basic_protection()
                print(f"{Fore.GREEN}Basic protection rules applied.{Style.RESET_ALL}")
                input("\nPress Enter to continue...")
            elif choice == "4":
                break
            else:
                print(f"{Fore.RED}Invalid choice. Please try again.{Style.RESET_ALL}")
                input("\nPress Enter to continue...")

    def view_firewall_rules(self):
        """View current firewall rules"""
        os.system('clear')
        try:
            print(f"\n{Fore.CYAN}=== Current Firewall Rules ==={Style.RESET_ALL}\n")
            result = subprocess.run(['iptables', '-L', '-n', '--line-numbers'], capture_output=True, text=True)
            
            # Format and colorize the output
            for line in result.stdout.split('\n'):
                if "Chain" in line:
                    print(f"{Fore.YELLOW}{line}{Style.RESET_ALL}")
                elif "target" in line:
                    print(f"{Fore.CYAN}{line}{Style.RESET_ALL}")
                elif "DROP" in line:
                    print(f"{Fore.RED}{line}{Style.RESET_ALL}")
                elif "ACCEPT" in line:
                    print(f"{Fore.GREEN}{line}{Style.RESET_ALL}")
                else:
                    print(line)
        except Exception as e:
            print(f"{Fore.RED}Error viewing firewall rules: {str(e)}{Style.RESET_ALL}")
        
        input("\nPress Enter to return to Firewall Settings...")

    def reset_iptables_rules(self):
        """Reset all IPTables rules and restore default policy with enhanced confirmations"""
        try:
            # First confirmation
            print(f"\n{Fore.RED}WARNING: This will reset all IPTables rules!{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}This action will:{Style.RESET_ALL}")
            print("1. Clear all existing firewall rules")
            print("2. Reset all chains to default policy")
            print("3. Remove all custom chains")
            confirm1 = input("\nProceed? [y/N]: ").lower() or 'n'
            
            if confirm1 != 'y':
                print(f"{Fore.YELLOW}Operation cancelled.{Style.RESET_ALL}")
                return
            
            # Second confirmation - Tor warning
            print(f"\n{Fore.RED}IMPORTANT TOR NETWORK WARNING:{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}Resetting IPTables rules will:{Style.RESET_ALL}")
            print("1. Disable any existing Tor routing rules")
            print("2. Potentially expose your real IP address")
            print("3. Break anonymity if you're using Tor")
            confirm2 = input("\nConfirm you are NOT using Tor? [y/N]: ").lower() or 'n'
            
            if confirm2 != 'y':
                print(f"{Fore.YELLOW}Operation cancelled for your security.{Style.RESET_ALL}")
                return
            
            # Final confirmation
            print(f"\n{Fore.RED}FINAL CONFIRMATION:{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}Please confirm that:{Style.RESET_ALL}")
            print("1. You understand all current firewall rules will be deleted")
            print("2. You are NOT using Tor for anonymity")
            print("3. You accept the security implications")
            confirm3 = input("\nAre you absolutely sure? [y/N]: ").lower() or 'n'
            
            if confirm3 != 'y':
                print(f"{Fore.YELLOW}Operation cancelled.{Style.RESET_ALL}")
                return
            
            # Proceed with reset
            print(f"\n{Fore.YELLOW}Resetting IPTables rules...{Style.RESET_ALL}")
            
            # Flush all rules
            subprocess.run(['iptables', '-F'], check=True)
            subprocess.run(['iptables', '-X'], check=True)
            subprocess.run(['iptables', '-t', 'nat', '-F'], check=True)
            subprocess.run(['iptables', '-t', 'nat', '-X'], check=True)
            subprocess.run(['iptables', '-t', 'mangle', '-F'], check=True)
            subprocess.run(['iptables', '-t', 'mangle', '-X'], check=True)
            
            # Set default policies to ACCEPT
            subprocess.run(['iptables', '-P', 'INPUT', 'ACCEPT'], check=True)
            subprocess.run(['iptables', '-P', 'FORWARD', 'ACCEPT'], check=True)
            subprocess.run(['iptables', '-P', 'OUTPUT', 'ACCEPT'], check=True)
            
            # Clear blocked IPs list
            self.blocked_ips.clear()
            
            print(f"{Fore.GREEN}Successfully reset all IPTables rules.{Style.RESET_ALL}")
            logging.info("IPTables rules reset by user after triple confirmation")
            
        except Exception as e:
            print(f"{Fore.RED}Error resetting IPTables rules: {str(e)}{Style.RESET_ALL}")
            logging.error(f"Error resetting IPTables rules: {str(e)}")
        
        input("\nPress Enter to continue...")

    def apply_basic_protection(self):
        """Apply basic protection rules"""
        try:
            # First clean up existing rules
            self.reset_iptables_rules()
            
            # Set default policies
            subprocess.run(['iptables', '-P', 'INPUT', 'DROP'], check=True)
            subprocess.run(['iptables', '-P', 'FORWARD', 'DROP'], check=True)
            subprocess.run(['iptables', '-P', 'OUTPUT', 'ACCEPT'], check=True)
            
            # Allow loopback traffic
            subprocess.run(['iptables', '-A', 'INPUT', '-i', 'lo', '-j', 'ACCEPT'], check=True)
            
            # Allow established connections
            subprocess.run(['iptables', '-A', 'INPUT', '-m', 'conntrack', '--ctstate', 'ESTABLISHED,RELATED', '-j', 'ACCEPT'], check=True)
            
            # Allow all traffic from local network
            for network in ['192.168.0.0/16', '10.0.0.0/8', '172.16.0.0/12']:
                subprocess.run(['iptables', '-A', 'INPUT', '-s', network, '-j', 'ACCEPT'], check=True)
            
            # Allow common services
            common_ports = [
                ('tcp', '22'),    # SSH
                ('tcp', '80'),    # HTTP
                ('tcp', '443'),   # HTTPS
                ('udp', '53'),    # DNS
                ('tcp', '53'),    # DNS
                ('udp', '67:68'), # DHCP
                ('tcp', '21'),    # FTP
                ('tcp', '990'),   # FTPS
                ('tcp', '143'),   # IMAP
                ('tcp', '993'),   # IMAPS
                ('tcp', '110'),   # POP3
                ('tcp', '995'),   # POP3S
                ('tcp', '25'),    # SMTP
                ('tcp', '587'),   # SMTP
                ('tcp', '465'),   # SMTPS
                ('udp', '123'),   # NTP
            ]
            
            for proto, port in common_ports:
                subprocess.run(['iptables', '-A', 'INPUT', '-p', proto, '--dport', port, '-j', 'ACCEPT'], check=True)
            
            # Allow ping requests with rate limiting
            subprocess.run(['iptables', '-A', 'INPUT', '-p', 'icmp', '--icmp-type', 'echo-request', 
                          '-m', 'limit', '--limit', '1/s', '-j', 'ACCEPT'], check=True)
            
            # Block IPs in the blacklist
            for ip in self.blacklist:
                subprocess.run(['iptables', '-A', 'INPUT', '-s', ip, '-j', 'DROP'], check=True)
                self.blocked_ips[ip] = {
                    'timestamp': time.time(),
                    'reason': 'Blacklisted'
                }
            
            logging.info("Basic protection rules applied")
            print(f"{Fore.GREEN}Basic protection rules applied successfully.{Style.RESET_ALL}")
            
        except Exception as e:
            logging.error(f"Error applying basic protection rules: {str(e)}")
            print(f"{Fore.RED}Error applying protection rules: {str(e)}{Style.RESET_ALL}")

    def show_help(self):
        print(f"\n{Fore.CYAN}=== OpenMammoth Help ==={Style.RESET_ALL}")
        print("OpenMammoth is a network protection tool that helps secure your system")
        print("against various types of cyber attacks.")
        print("\nMain Features:")
        print("- Real-time packet analysis with multi-threading support")
        print("- Thread-safe data processing for high-concurrency environments")
        print("- Multiple protection levels with intelligent false positive reduction")
        print("- Advanced attack detection with context-aware analysis")
        print("- IP blocking system with whitelist protection")
        print("- Detailed statistics and comprehensive monitoring")
        print("- Whitelist and blacklist management")
        print("- Threat intelligence integration")
        print("- Automatic updates")
        print("- Comprehensive firewall rules management")
        print("\nProtection Levels:")
        print("1. Basic - Minimal protection, low resource usage")
        print("2. Standard - Balanced protection")
        print("3. Enhanced - Strong protection")
        print("4. Extreme - Maximum protection")
        print("\nAdvanced Protection:")
        print("When enabled, additional security checks are performed including:")
        print("- TTL anomaly detection")
        print("- TCP sequence prediction attacks")
        print("- Stealth scan detection (Null, FIN, XMAS scans)")
        print("- Intelligent port scan detection with reduced false positives")
        print("- SYN flood protection with legitimate connection detection")
        print("\nFalse Positive Reduction:")
        print("- Pattern-based traffic analysis to identify legitimate services")
        print("- Context-aware traffic evaluation for common usage patterns")
        print("- Connection tracking to identify established legitimate sessions")
        print("- Port pattern recognition for normal service discovery")
        print("- Adaptive thresholds based on traffic history")
        print("\nThread Safety:")
        print("- Fine-grained locking for shared data structures")
        print("- Protected concurrent access to packet tracking information")
        print("- Thread pool executor for parallel packet processing")
        print("- Memory-efficient data structures with automatic cleanup")
        print("\nThreat Intelligence:")
        print("When enabled, OpenMammoth uses external threat intelligence")
        print("to identify and block known malicious IP addresses.")
        print("\nFor more information, visit the GitHub repository.")
        
        input("\nPress Enter to return to main menu...")

    def show_about(self):
        print(f"\n{Fore.CYAN}=== About OpenMammoth ==={Style.RESET_ALL}")
        print(f"{Fore.YELLOW}Version: 2.1{Style.RESET_ALL}")
        print(f"{Fore.GREEN}Author: root0emir{Style.RESET_ALL}")
        print(f"{Fore.BLUE}License: MIT{Style.RESET_ALL}")
        print("\nOpenMammoth is a powerful network protection tool designed to")
        print("secure your system against various types of cyber attacks.")
        print("This version is a OpenMammoth Securonis Edition Forked and optimized for Securonis Linux ")
        print("\nFeatures:")
        print(f"{Fore.GREEN}✓{Style.RESET_ALL} Real-time packet analysis with multi-threading support")
        print(f"{Fore.GREEN}✓{Style.RESET_ALL} Thread-safe data structures for concurrent processing")
        print(f"{Fore.GREEN}✓{Style.RESET_ALL} Multiple protection levels with false positive reduction")
        print(f"{Fore.GREEN}✓{Style.RESET_ALL} Advanced attack detection with context awareness")
        print(f"{Fore.GREEN}✓{Style.RESET_ALL} IP blocking with intelligent service recognition")
        print(f"{Fore.GREEN}✓{Style.RESET_ALL} Detailed statistics and system impact monitoring")
        print(f"{Fore.GREEN}✓{Style.RESET_ALL} Customizable settings with graceful resource management")
        print("\nNew in Version 2.1:")
        print(f"{Fore.CYAN}•{Style.RESET_ALL} Thread-safe data access with proper locking mechanisms")
        print(f"{Fore.CYAN}•{Style.RESET_ALL} Intelligent SYN flood detection with reduced false positives")
        print(f"{Fore.CYAN}•{Style.RESET_ALL} Context-aware port scan detection")
        print(f"{Fore.CYAN}•{Style.RESET_ALL} Service pattern recognition to whitelist legitimate traffic")
        print(f"{Fore.CYAN}•{Style.RESET_ALL} Memory optimization with adaptive data cleanup")
        print("\nSupported Attack Types:")
        print(f"{Fore.RED}•{Style.RESET_ALL} Port Scanning (with improved accuracy)")
        print(f"{Fore.RED}•{Style.RESET_ALL} SYN Flood (with reduced false positives)")
        print(f"{Fore.RED}•{Style.RESET_ALL} UDP Flood")
        print(f"{Fore.RED}•{Style.RESET_ALL} ICMP Flood")
        print(f"{Fore.RED}•{Style.RESET_ALL} DNS Amplification")
        print(f"{Fore.RED}•{Style.RESET_ALL} Fragment Attacks")
        print(f"{Fore.RED}•{Style.RESET_ALL} Malformed Packets")
        print(f"{Fore.RED}•{Style.RESET_ALL} IP Spoofing")
        print(f"{Fore.RED}•{Style.RESET_ALL} Application Layer Attacks")
        print(f"\n{Fore.CYAN}GitHub: https://github.com/Securonis/OpenMammoth {Style.RESET_ALL}")
        input("\nPress Enter to return to main menu...")

    def get_available_interfaces(self):
        """Get available network interfaces"""
        interfaces = []
        try:
            # Use ip command to get interface information
            ip_output = subprocess.check_output(['ip', 'addr', 'show'], text=True)
            current_interface = None
            
            for line in ip_output.split('\n'):
                # Match interface line
                if line and not line.startswith(' '):
                    interface_match = re.match(r'\d+:\s+([^:@]+)[:.@]', line)
                    if interface_match:
                        current_interface = {
                            'name': interface_match.group(1),
                            'ip': '',
                            'mac': '',
                            'status': 'DOWN'
                        }
                        if 'UP' in line:
                            current_interface['status'] = 'UP'
                        interfaces.append(current_interface)
                
                # Match IP address line
                elif current_interface and 'inet ' in line:
                    ip_match = re.search(r'inet\s+([0-9.]+)/', line)
                    if ip_match:
                        current_interface['ip'] = ip_match.group(1)
                
                # Match MAC address line
                elif current_interface and 'link/ether' in line:
                    mac_match = re.search(r'link/ether\s+([0-9a-fA-F:]+)', line)
                    if mac_match:
                        current_interface['mac'] = mac_match.group(1)

            # Filter out interfaces without IP addresses (except lo)
            interfaces = [iface for iface in interfaces if iface['ip'] or iface['name'] == 'lo']
            
            if not interfaces:
                logging.warning("No network interfaces found with IP addresses")
            else:
                logging.info(f"Found {len(interfaces)} network interfaces")
                
            return interfaces
            
        except subprocess.CalledProcessError as e:
            logging.error(f"Error running ip command: {str(e)}")
            return []
        except Exception as e:
            logging.error(f"Error getting network interfaces: {str(e)}")
            return []

    def display_interfaces(self):
        """Display network interfaces"""
        print(f"\n{Fore.CYAN}=== Available Network Interfaces ==={Style.RESET_ALL}")
        if not self.available_interfaces:
            print(f"{Fore.RED}Warning: No network interfaces found!{Style.RESET_ALL}")
            return False
        
        for idx, iface in enumerate(self.available_interfaces, 1):
            print(f"{idx}. {iface['name']}")
            print(f"   IP: {iface['ip']}")
            print(f"   MAC: {iface['mac']}")
            print(f"   Status: {iface['status']}")
            print("-" * 40)
        return True

    def select_interface(self):
        """Select network interface"""
        if not self.available_interfaces:
            print(f"{Fore.RED}Warning: No network interfaces found!{Style.RESET_ALL}")
            return False
        
        if not self.display_interfaces():
            return False
        
        while True:
            try:
                choice = input("\nSelect interface (1-{}) or 'q' to quit: ".format(len(self.available_interfaces)))
                if choice.lower() == 'q':
                    return False
                
                idx = int(choice) - 1
                if 0 <= idx < len(self.available_interfaces):
                    self.interface = self.available_interfaces[idx]['name']
                    print(f"{Fore.GREEN}Selected interface: {self.interface}{Style.RESET_ALL}")
                    return True
                else:
                    print(f"{Fore.RED}Invalid selection! Please select an interface from the list.{Style.RESET_ALL}")
            except ValueError:
                print(f"{Fore.RED}Please enter a valid number!{Style.RESET_ALL}")

    def load_threat_intel(self):
        try:
            intel_path = os.path.join(self.config_dir, 'threat_intel.json')
            if os.path.exists(intel_path):
                with open(intel_path, 'r') as f:
                    self.threat_intel_db = json.load(f)
                    logging.info(f"Loaded {len(self.threat_intel_db)} threat intelligence entries")
            else:

                self.update_threat_intel()
        except Exception as e:
            logging.error(f"Error loading threat intelligence: {str(e)}")
            self.threat_intel_db = {}

    def update_threat_intel(self):
        """Update threat intelligence database"""
        try:
            # This function requires internet connection
            if not self.check_internet_connection():
                logging.warning("No internet connection available for threat intel update")
                return False
                
            logging.info("Updating threat intelligence database...")
            
            # Fetch threat list from trusted sources (example URLs)
            sources = [
                "https://raw.githubusercontent.com/stamparm/ipsum/master/ipsum.txt",
                "https://raw.githubusercontent.com/firehol/blocklist-ipsets/master/firehol_level1.netset"
            ]
            
            updated_db = {}
            sources_success = 0
            for source in sources:
                try:
                    response = requests.get(source, timeout=10)
                    if response.status_code == 200:
                        # Process IP addresses line by line
                        count_before = len(updated_db)
                        for line in response.text.split("\n"):
                            line = line.strip()
                            # Skip comment lines and empty lines
                            if not line or line.startswith("#"):
                                continue
                            
                            # Split IP address and other information
                            parts = line.split()
                            ip = parts[0]
                            
                            # Validate IP address
                            try:
                                ipaddress.ip_address(ip)
                                # Don't add local IPs and whitelisted IPs as threats
                                if ip not in self.local_ips and ip not in self.whitelist:
                                    updated_db[ip] = {
                                        "source": source,
                                        "timestamp": time.time(),
                                        "score": 100  # Default threat score
                                    }
                            except ValueError:
                                continue
                        
                        sources_success += 1
                        ips_added = len(updated_db) - count_before
                        logging.info(f"Added {ips_added} IPs from {source}")
                    else:
                        logging.warning(f"Failed to fetch threat data from {source}: Status code {response.status_code}")
                except Exception as e:
                    logging.error(f"Error fetching threat data from {source}: {str(e)}")
            
            if updated_db and sources_success > 0:
                old_count = len(self.threat_intel_db)
                self.threat_intel_db = updated_db
                
                # Save database to disk
                intel_path = os.path.join(self.config_dir, 'threat_intel.json')
                try:
                    with open(intel_path, 'w') as f:
                        json.dump(self.threat_intel_db, f, indent=4)
                    logging.info(f"Updated threat intelligence database with {len(updated_db)} entries (was {old_count})")
                except Exception as e:
                    logging.error(f"Error saving threat intelligence database: {str(e)}")
                    
                self.last_update_check = time.time()
                self.save_config()
                return True
            else:
                logging.warning("No threat intelligence data was updated")
                return False
        except Exception as e:
            logging.error(f"Error updating threat intelligence: {str(e)}")
            return False

    def check_internet_connection(self):
        """Check internet connection"""
        try:
            # Try to connect to Google DNS
            socket.create_connection(("8.8.8.8", 53), timeout=3)
            return True
        except OSError:
            try:
                # Try to connect to Cloudflare DNS
                socket.create_connection(("1.1.1.1", 53), timeout=3)
                return True
            except OSError:
                pass
        except Exception:
            pass
        return False

    def load_ip_lists(self):
        """Load whitelist and blacklist"""
        try:
            # Load whitelist file
            whitelist_path = os.path.join(self.config_dir, 'whitelist.txt')
            if os.path.exists(whitelist_path):
                with open(whitelist_path, 'r') as f:
                    self.whitelist = [line.strip() for line in f if line.strip() and not line.startswith("#")]
                logging.info(f"Loaded {len(self.whitelist)} whitelisted IPs")
            
            # Load blacklist file
            blacklist_path = os.path.join(self.config_dir, 'blacklist.txt')
            if os.path.exists(blacklist_path):
                with open(blacklist_path, 'r') as f:
                    self.blacklist = [line.strip() for line in f if line.strip() and not line.startswith("#")]
                logging.info(f"Loaded {len(self.blacklist)} blacklisted IPs")
                
                # Block IPs in the blacklist
                for ip in self.blacklist:
                    if ip not in self.blocked_ips:
                        self.block_ip(ip, reason="Blacklisted")
        except Exception as e:
            logging.error(f"Error loading IP lists: {str(e)}")

    def save_ip_lists(self):
        """Save whitelist and blacklist"""
        try:
            # Save whitelist
            whitelist_path = os.path.join(self.config_dir, 'whitelist.txt')
            with open(whitelist_path, 'w') as f:
                f.write("# OpenMammoth Whitelist\n")
                f.write("# Format: One IP per line\n")
                for ip in self.whitelist:
                    f.write(f"{ip}\n")
            
            # Save blacklist
            blacklist_path = os.path.join(self.config_dir, 'blacklist.txt')
            with open(blacklist_path, 'w') as f:
                f.write("# OpenMammoth Blacklist\n")
                f.write("# Format: One IP per line\n")
                for ip in self.blacklist:
                    f.write(f"{ip}\n")
            
            logging.info("IP lists saved successfully")
        except Exception as e:
            logging.error(f"Error saving IP lists: {str(e)}")

    def is_ip_in_blacklist(self, ip):
        """Check if IP is in blacklist"""
        return ip in self.blacklist

    def is_ip_in_whitelist(self, ip):
        """Check if IP is in whitelist"""
        return ip in self.whitelist

    def is_ip_in_threat_intel(self, ip):
        """Check if IP is in threat intelligence database"""
        return ip in self.threat_intel_db

    def check_ip_reputation(self, ip):
        """Gelişmiş IP itibar kontrolü ve tehdit istihbaratı entegrasyonu"""
        # Initialize reputation tracking if not exists
        if not hasattr(self, 'reputation_cache'):
            self.reputation_cache = {}
            self.high_risk_countries = ['KP', 'IR', 'RU', 'CN']  # Example high-risk countries
            self.use_external_threat_api = self.advanced_protection  # Only use external APIs in advanced mode
        
        # Skip checking local IPs and whitelisted IPs
        if self.is_local_network(ip) or self.is_ip_in_whitelist(ip):
            return False
        
        # Check if it's in the blacklist (instant block)
        if self.is_ip_in_blacklist(ip):
            self.stats['reputation_blocks'] += 1
            if ip not in self.reputation_cache:
                self.reputation_cache[ip] = {
                    'score': 100,  # Maximum score
                    'last_check': time.time(),
                    'reasons': ['Manual blacklist'],
                    'source': 'local'
                }
            return True
        
        current_time = time.time()
        
        # Check if we have a cached result that's still valid (30 minute cache)
        if ip in self.reputation_cache:
            # Only use cache if it's less than 30 minutes old
            if current_time - self.reputation_cache[ip]['last_check'] < 1800:  # 30 minutes
                if self.reputation_cache[ip]['score'] >= 80:  # Very high risk
                    self.stats['reputation_blocks'] += 1
                    return True
                return False
        
        # Initialize reputation score and evidence
        rep_score = 0
        reasons = []
        
        # Layer 1: Check local threat database
        if self.use_threat_intel and self.is_ip_in_threat_intel(ip):
            self.stats['threat_intel_blocks'] += 1
            threat_info = self.threat_intel_db.get(ip, {'score': 80, 'reason': 'Known malicious'})
            rep_score += min(90, threat_info.get('score', 80))  # Cap at 90
            reasons.append(f"Threat DB: {threat_info.get('reason', 'Known malicious')}")
        
        # Layer 2: Check IP reputation database
        if hasattr(self, 'ip_reputation_db') and ip in self.ip_reputation_db:
            reputation = self.ip_reputation_db[ip]
            rep_score = max(rep_score, min(85, reputation.get('score', 0)))
            if 'category' in reputation:
                reasons.append(f"Rep DB: {reputation['category']}")
        
        # Layer 3: Analyze behavior history if available
        if hasattr(self, 'connection_tracker'):
            conn_key_prefix = f"{ip}-"
            conn_count = 0
            rejected_count = 0
            ports = set()
            
            # Count connections from this IP
            for key, data in self.connection_tracker.items():
                if key.startswith(conn_key_prefix):
                    conn_count += data.get('count', 0)
                    if 'rejected' in data and data['rejected']:
                        rejected_count += 1
                    # Extract destination port if available
                    parts = key.split('-')
                    if len(parts) > 2 and ':' in parts[1]:
                        try:
                            port = int(parts[1].split(':')[1])
                            ports.add(port)
                        except:
                            pass
            
            # Check connection rate
            if conn_count > 1000:  # Very high connection rate
                rep_score += 30
                reasons.append("High connection rate")
            elif conn_count > 500:
                rep_score += 15
                reasons.append("Elevated connection rate")
            
            # Check rejected connection attempts
            if rejected_count > 20:
                rep_score += 25
                reasons.append("Multiple rejected connections")
            
            # Check for suspicious port access patterns
            if len(ports) > 100:  # Accessing many different ports
                rep_score += 20
                reasons.append("Unusual port access pattern")
        
        # Layer 4: Check for network scanning behavior
        if hasattr(self, 'port_scan_tracker') and ip in self.port_scan_tracker:
            scan_data = self.port_scan_tracker[ip]
            if scan_data.get('scan_detection_count', 0) > 0:
                scan_penalty = min(40, scan_data.get('scan_detection_count', 0) * 10)
                rep_score += scan_penalty
                reasons.append(f"Port scanning activity ({scan_data.get('scan_detection_count', 0)} instances)")
        
        # Layer 5: Geographic location check (if available)
        if hasattr(self, 'geo_db') and ip in getattr(self, 'geo_db', {}):
            country = self.geo_db[ip].get('country', '')
            if country in self.high_risk_countries:
                rep_score += 15
                reasons.append(f"High-risk country: {country}")
            
        # Layer 6: Check behavioral markers
        attack_markers = 0
        
        # Check TTL anomalies
        if hasattr(self, 'ttl_tracker') and ip in self.ttl_tracker:
            ttl_data = self.ttl_tracker[ip]
            if len(ttl_data.get('values', [])) >= 3:
                # Calculate standard deviation
                ttl_values = ttl_data['values'][-10:]  # Last 10 values
                avg = sum(ttl_values) / len(ttl_values)
                variance = sum((x - avg) ** 2 for x in ttl_values) / len(ttl_values)
                std_dev = variance ** 0.5
                
                if std_dev > 5:
                    attack_markers += 1
                    rep_score += 15
                    reasons.append("TTL manipulation detected")
        
        # Check TCP sequence anomalies
        if hasattr(self, 'seq_tracker') and ip in self.seq_tracker:
            seq_data = self.seq_tracker[ip]
            if seq_data.get('prediction_attempts', 0) > 0:
                attack_markers += 1
                rep_score += 20
                reasons.append("TCP sequence anomalies")
        
        # Malformed packet history
        if hasattr(self, 'malformed_packet_history') and ip in getattr(self, 'malformed_packet_history', {}):
            malformed_count = self.malformed_packet_history[ip].get('count', 0)
            if malformed_count > 3:
                attack_markers += 1
                rep_score += min(25, malformed_count * 5)
                reasons.append(f"Malformed packets ({malformed_count})")
        
        # Fragment attack history
        if hasattr(self, 'fragment_attack_history') and ip in getattr(self, 'fragment_attack_history', {}):
            frag_count = self.fragment_attack_history[ip].get('count', 0)
            if frag_count > 0:
                attack_markers += 1
                rep_score += min(30, frag_count * 10)
                reasons.append(f"Fragment attacks ({frag_count})")
        
        # If we have multiple attack markers, increase reputation impact
        if attack_markers >= 2:
            rep_score += 20
            reasons.append("Multiple attack signatures")
        
        # Store the result in cache
        self.reputation_cache[ip] = {
            'score': rep_score,
            'last_check': current_time,
            'reasons': reasons,
            'source': 'composite'
        }
        
        # Return decision based on reputation score
        # Very high risk IPs are automatically blocked
        if rep_score >= 80:
            logging.warning(f"High-risk IP detected ({ip}): {rep_score}/100 - {', '.join(reasons)}")
            self.stats['reputation_blocks'] += 1
            return True
        
        # Log suspicious but not blocked IPs
        if rep_score >= 50:
            logging.info(f"Suspicious IP detected ({ip}): {rep_score}/100 - {', '.join(reasons)}")
        
        return False

    def check_for_updates(self):
        """Check for new threat database updates"""
        try:
            current_time = time.time()
            
            # If enough time has passed since the last update check
            if current_time - self.last_update_check > self.update_interval:
                logging.info("Checking for threat intelligence updates")
                
                # Check internet connection
                if not self.check_internet_connection():
                    logging.error("No internet connection available for update check")
                    return False
                
                # Update threat intelligence database
                if self.use_threat_intel:
                    if self.update_threat_intel():
                        print(f"{Fore.GREEN}Threat intelligence database updated successfully.{Style.RESET_ALL}")
                    else:
                        print(f"{Fore.YELLOW}Failed to update threat intelligence database.{Style.RESET_ALL}")
                
                # Save last update time
                self.last_update_check = current_time
                self.save_config()
                
                return True
        except Exception as e:
            logging.error(f"Error checking for updates: {str(e)}")
        
        return False

    def add_to_whitelist(self, ip):
        """Add IP address to whitelist"""
        try:
            # Validate IP address format
            ipaddress.ip_address(ip)
            
            # If IP is not already in whitelist
            if ip not in self.whitelist:
                self.whitelist.append(ip)
                
                # If IP is in blacklist or blocked IPs, remove it
                if ip in self.blacklist:
                    self.blacklist.remove(ip)
                
                if ip in self.blocked_ips:
                    # Remove blocking rule
                    try:
                        subprocess.run(
                            ['iptables', '-D', 'INPUT', '-s', ip, '-j', 'DROP'],
                            capture_output=True, text=True, check=True
                        )
                    except Exception:
                        pass
                    del self.blocked_ips[ip]
                
                # Save lists
                self.save_ip_lists()
                
                logging.info(f"Added IP to whitelist: {ip}")
                return True
            return False
        except ValueError:
            logging.error(f"Invalid IP address format: {ip}")
            return False
        except Exception as e:
            logging.error(f"Error adding IP to whitelist: {str(e)}")
            return False

    def add_to_blacklist(self, ip):
        """Add IP address to blacklist"""
        try:
            # Validate IP address format
            ipaddress.ip_address(ip)
            
            # If IP is not already in blacklist
            if ip not in self.blacklist:
                # If IP is in whitelist, warn and cancel
                if ip in self.whitelist:
                    logging.warning(f"Cannot blacklist whitelisted IP: {ip}")
                    return False
                
                self.blacklist.append(ip)
                
                # If IP is not already blocked, block it
                if ip not in self.blocked_ips:
                    self.block_ip(ip, reason="Blacklisted")
                
                # Save lists
                self.save_ip_lists()
                
                logging.info(f"Added IP to blacklist: {ip}")
                return True
            return False
        except ValueError:
            logging.error(f"Invalid IP address format: {ip}")
            return False
        except Exception as e:
            logging.error(f"Error adding IP to blacklist: {str(e)}")
            return False

    def check_root_permissions(self):
        """Check if the script is running with root/administrator privileges"""
        try:
            # Unix (Linux/MacOS) - check for effective user ID 0 (root)
            if os.name == 'posix':
                return os.geteuid() == 0
            # Windows - attempt to access a privileged file
            elif os.name == 'nt':
                try:
                    # Try to open a system file that requires admin privileges
                    temp = open(os.path.join(os.environ.get('windir', 'C:\\Windows'), 'system.ini'), 'a')
                    temp.close()
                    return True
                except PermissionError:
                    return False
            return False  # Default for unknown OS
        except Exception as e:
            logging.error(f"Error checking root permissions: {str(e)}")
            return False

    def check_system_requirements(self):
        """Check basic system requirements"""
        # Check for required packages
        try:
            # Check Scapy functionality
            if not hasattr(scapy, 'all'):
                print(f"{Fore.RED}Error: Scapy not fully functional{Style.RESET_ALL}")
                sys.exit(1)
                
            # Check for iptables on Linux
            if os.name == 'posix':
                try:
                    subprocess.run(['iptables', '--version'], 
                                  stdout=subprocess.PIPE, 
                                  stderr=subprocess.PIPE, 
                                  check=True)
                except (subprocess.SubprocessError, FileNotFoundError):
                    print(f"{Fore.YELLOW}Warning: iptables not found. Some protection features will be limited.{Style.RESET_ALL}")
                    logging.warning("iptables not found. Some protection features will be limited.")
        except Exception as e:
            logging.error(f"Error checking system requirements: {str(e)}")
            print(f"{Fore.RED}Error checking system requirements: {str(e)}{Style.RESET_ALL}")
            sys.exit(1)

        # Check if iptables is installed
        try:
            iptables_check = subprocess.run(
                ['which', 'iptables'], 
                capture_output=True, 
                text=True
            )
            if iptables_check.returncode != 0:
                print(f"{Fore.RED}Error: iptables is not installed!{Style.RESET_ALL}")
                print(f"{Fore.YELLOW}Please install iptables: 'sudo apt-get install iptables'{Style.RESET_ALL}")
                sys.exit(1)
        except Exception as e:
            print(f"{Fore.RED}Error checking system requirements: {str(e)}{Style.RESET_ALL}")
            
        # Check if we have root privileges
        if os.geteuid() != 0:
            print(f"{Fore.RED}Error: This program must be run as root.{Style.RESET_ALL}")
            sys.exit(1)
    
    def detect_local_ips(self):
        """Detect local IP addresses and add them to whitelist"""
        try:
            # Get all network interfaces
            for iface in self.available_interfaces:
                if 'ip' in iface and iface['ip'] != '127.0.0.1':
                    self.local_ips.append(iface['ip'])
                    # Automatically add local IPs to whitelist
                    if iface['ip'] not in self.whitelist:
                        self.whitelist.append(iface['ip'])
            
            # Loopback address should always be in whitelist
            if '127.0.0.1' not in self.whitelist:
                self.whitelist.append('127.0.0.1')
                
            if self.local_ips:
                logging.info(f"Detected local IPs: {', '.join(self.local_ips)}")
        except Exception as e:
            logging.error(f"Error detecting local IPs: {str(e)}")

    def configure_interfaces(self):
        """Configure network interfaces"""
        print(f"\n{Fore.CYAN}=== Network Interface Configuration ==={Style.RESET_ALL}")
        
        # Refresh available interfaces
        self.available_interfaces = self.get_available_interfaces()
        
        if not self.available_interfaces:
            print(f"{Fore.RED}Error: No network interfaces detected!{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}Please check your network connections and try again.{Style.RESET_ALL}")
            print("\nPossible solutions:")
            print("1. Make sure your network hardware is properly connected")
            print("2. Run 'ip link' or 'ifconfig' to check interface status")
            print("3. Use 'ip link set <interface> up' to bring up interfaces")
            input("\nPress Enter to return to main menu...")
            return
        
        # Display available interfaces and select one
        self.select_interface()

    def view_protection_status(self):
        """View current protection status"""
        os.system('clear')
        print(f"\n{Fore.CYAN}=== Protection Status ==={Style.RESET_ALL}")
        
        if self.is_running:
            uptime = time.time() - self.start_time
            hours, remainder = divmod(uptime, 3600)
            minutes, seconds = divmod(remainder, 60)
            
            print(f"\n{Fore.GREEN}[+] Protection Status: ACTIVE{Style.RESET_ALL}")
            print(f"{Fore.CYAN}[*] Interface: {self.interface}{Style.RESET_ALL}")
            print(f"{Fore.CYAN}[*] Protection Level: {self.protection_level}{Style.RESET_ALL}")
            print(f"{Fore.CYAN}[*] Advanced Protection: {'Enabled' if self.advanced_protection else 'Disabled'}{Style.RESET_ALL}")
            print(f"{Fore.CYAN}[*] Threat Intelligence: {'Enabled' if self.use_threat_intel else 'Disabled'}{Style.RESET_ALL}")
            print(f"{Fore.CYAN}[*] Uptime: {int(hours)}h {int(minutes)}m {int(seconds)}s{Style.RESET_ALL}")
            print(f"\n{Fore.YELLOW}Current Statistics:{Style.RESET_ALL}")
            print(f"Total Packets: {self.stats['total_packets']}")
            print(f"Blocked Packets: {self.stats['blocked_packets']}")
            print(f"Attacks Detected: {self.stats['attacks_detected']}")
            print(f"Active Blocks: {len(self.blocked_ips)}")
        else:
            print(f"\n{Fore.RED}[!] Protection Status: INACTIVE{Style.RESET_ALL}")
            print(f"\n{Fore.YELLOW}Use 'Start Protection' to enable network protection.{Style.RESET_ALL}")
        
        input("\nPress Enter to return to main menu...")

    def is_local_network(self, ip):
        """Enhanced check for local network IPs"""
        try:
            ip_obj = ipaddress.ip_address(ip)
            
            # Check if IP is in local networks list
            if ip in self.local_ips:
                return True
            
            # Check common local IP patterns
            if ip.startswith('192.168.') or ip.startswith('10.') or ip.startswith('172.'):
                return True
            
            # Check if IP is router/gateway
            if ip.endswith('.1') or ip.endswith('.254'):
                return True
            
            # Check private IP ranges
            return any([
                ip_obj in ipaddress.ip_network('10.0.0.0/8'),
                ip_obj in ipaddress.ip_network('172.16.0.0/12'),
                ip_obj in ipaddress.ip_network('192.168.0.0/16'),
                ip_obj in ipaddress.ip_network('127.0.0.0/8'),
                ip_obj in ipaddress.ip_network('169.254.0.0/16')  # Link-local addresses
            ])
        except ValueError:
            return False

    def check_application_layer_attacks(self, packet):
        """Detect application layer attacks like SQLi, XSS, Path Traversal in HTTP/HTTPS traffic"""
        if not TCP in packet:
            return False
            
        # Check if this is HTTP/HTTPS traffic
        tcp_dport = packet[TCP].dport
        tcp_sport = packet[TCP].sport
        ip_src = packet[IP].src
        
        # HTTP/HTTPS ports
        http_ports = [80, 8080, 8000, 8008, 8088]
        https_ports = [443, 8443, 4443]
        
        is_http = (tcp_dport in http_ports) or (tcp_sport in http_ports)
        is_https = (tcp_dport in https_ports) or (tcp_sport in https_ports)
        
        if not (is_http or is_https):
            return False
        
        # Initialize attack signature database if needed
        if not hasattr(self, 'http_attack_signatures'):
            # Common attack signatures for SQLi, XSS, path traversal, etc.
            self.http_attack_signatures = {
                'sqli': [
                    b"' OR 1=1", b"' OR '1'='1", b"--", b";--", b"/*", b"*/", 
                    b"UNION SELECT", b"SELECT FROM", b"DROP TABLE", b"INSERT INTO",
                    b"1=1", b"OR 1=1", b"OR true", b"' OR true", b"\\x27 OR",
                    b"admin'--", b"' or #", b"benchmark("
                ],
                'xss': [
                    b"<script>", b"</script>", b"javascript:", b"onerror=", b"onload=",
                    b"eval(", b"document.cookie", b"<img src=x onerror=", b"alert(",
                    b"String.fromCharCode", b"iframe", b"onmouseover="
                ],
                'path_traversal': [
                    b"../", b"..\\\x5c", b"/etc/passwd", b"c:\\\x5cwindows", b"WEB-INF", 
                    b"../..", b"../../../", b"/boot.ini", b"wp-config.php", b"config.php"
                ],
                'command_injection': [
                    b"| ls", b"& ping", b"; whoami", b"|| id", b"& dir", b"; cat ", 
                    b"$(command)", b"`command`", b"; rm -rf", b":(){ :|:& };:"
                ],
                'file_inclusion': [
                    b"php://filter", b"data://", b"zip://", b"phar://", b"file://", 
                    b"gopher://", b"expect://", b"input://"
                ]
            }
            self.http_attacks_detected = {}
        
        # Track per-IP HTTP attack attempts
        if ip_src not in self.http_attacks_detected:
            self.http_attacks_detected[ip_src] = {
                'count': 0,
                'types': set(),
                'last_seen': time.time()
            }
        
        # Raw payload analysis
        raw_payload = bytes(packet[TCP].payload) if TCP in packet else b""
        if not raw_payload and Raw in packet:
            raw_payload = bytes(packet[Raw].load)
            
        if not raw_payload:
            return False
            
        # Deep packet inspection for HTTP attacks
        attack_types = []
        
        # Check for each attack type
        for attack_type, signatures in self.http_attack_signatures.items():
            for signature in signatures:
                if signature.lower() in raw_payload.lower():
                    attack_types.append(attack_type)
                    self.http_attacks_detected[ip_src]['types'].add(attack_type)
                    self.http_attacks_detected[ip_src]['count'] += 1
                    self.http_attacks_detected[ip_src]['last_seen'] = time.time()
                    
                    # Track in stats
                    attack_type_stat = f"{attack_type}_attacks"
                    if attack_type_stat not in self.stats:
                        self.stats[attack_type_stat] = 0
                    self.stats[attack_type_stat] += 1
                    
                    logging.warning(f"Detected {attack_type} attack in HTTP traffic from {ip_src}")
                    print(f"{Fore.RED}[!] {attack_type.upper()} attack detected from {ip_src}{Style.RESET_ALL}")
                    break  # Once we found one signature of this type, move to next type
        
        # Evaluate attack severity
        if attack_types:
            # Multiple attack types or repeated attacks are higher severity
            if len(attack_types) > 1 or self.http_attacks_detected[ip_src]['count'] > 3:
                return True  # Block immediately
            else:
                # For first few attempts, just log but don't block yet
                # This helps reduce false positives
                if self.http_attacks_detected[ip_src]['count'] <= 3:
                    logging.info(f"Potential {'/'.join(attack_types)} attack from {ip_src} (monitoring)")
                    return False
                else:
                    return True
                    
        return False

    def check_unusual_tcp_flags(self, packet):
        """Advanced analysis of TCP flags to detect unusual combinations and stealth techniques"""
        if not TCP in packet:
            return False
        
        # Get TCP flags
        flags = packet[TCP].flags
        ip_src = packet[IP].src
        tcp_dport = packet[TCP].dport
        current_time = time.time()
        
        # Initialize TCP flags tracker if not exists
        if not hasattr(self, 'tcp_flags_tracker'):
            self.tcp_flags_tracker = {}
            
        # Known suspicious flag combinations
        suspicious_combinations = [
            0x29,  # FIN-PSH-URG (XMAS scan)
            0x01,  # FIN only
            0x00,  # NULL scan
            0x40,  # ACK scan
            0x04,  # RST scan
            0x3F   # ALL flags set
        ]
        
        # Track flags from this source
        if ip_src not in self.tcp_flags_tracker:
            self.tcp_flags_tracker[ip_src] = {
                'flags_history': [flags],
                'first_seen': current_time,
                'last_seen': current_time,
                'ports_targeted': {tcp_dport: 1},
                'unusual_combinations': 0
            }
        else:
            tracker = self.tcp_flags_tracker[ip_src]
            tracker['flags_history'].append(flags)
            tracker['last_seen'] = current_time
            
            # Keep history manageable
            if len(tracker['flags_history']) > 20:
                tracker['flags_history'] = tracker['flags_history'][-20:]
                
            # Track targeted ports
            if tcp_dport in tracker['ports_targeted']:
                tracker['ports_targeted'][tcp_dport] += 1
            else:
                tracker['ports_targeted'][tcp_dport] = 1
        
        # Check for direct suspicious combinations
        if flags in suspicious_combinations:
            self.tcp_flags_tracker[ip_src]['unusual_combinations'] += 1
            logging.warning(f"Unusual TCP flags (0x{flags:02X}) detected from {ip_src} to port {tcp_dport}")
            print(f"{Fore.RED}[!] Unusual TCP flags combination detected from: {ip_src}{Style.RESET_ALL}")
            return True
        
        # Check for pattern-based detection
        if len(self.tcp_flags_tracker[ip_src]['flags_history']) >= 5:
            # Track variety of flags used
            unique_flags = set(self.tcp_flags_tracker[ip_src]['flags_history'])
            
            # Many different flag combinations in a short time = suspicious
            if len(unique_flags) >= 3 and len(self.tcp_flags_tracker[ip_src]['ports_targeted']) >= 3:
                time_span = current_time - self.tcp_flags_tracker[ip_src]['first_seen']
                if time_span < 30:  # Within 30 seconds
                    self.tcp_flags_tracker[ip_src]['unusual_combinations'] += 1
                    logging.warning(f"TCP flag manipulation pattern detected from {ip_src}: {len(unique_flags)} combinations")
                    print(f"{Fore.RED}[!] TCP flag manipulation pattern detected from: {ip_src}{Style.RESET_ALL}")
                    return True
        
        # Check high rate of unusual flags
        if hasattr(self.tcp_flags_tracker[ip_src], 'unusual_combinations') and \
           self.tcp_flags_tracker[ip_src]['unusual_combinations'] >= 3:
            logging.warning(f"Persistent TCP flag abuse from {ip_src}: {self.tcp_flags_tracker[ip_src]['unusual_combinations']} instances")
            print(f"{Fore.RED}[!] Persistent TCP flag abuse from: {ip_src}{Style.RESET_ALL}")
            return True
            
        return False

def main():
    if os.geteuid() != 0:
        print(f"{Fore.RED}Error: This program must be run as root.{Style.RESET_ALL}")
        sys.exit(1)
    
    tool = OpenMammoth()
    tool.display_menu()

if __name__ == "__main__":
    main()
